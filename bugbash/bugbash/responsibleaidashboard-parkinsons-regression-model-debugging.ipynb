{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98605bcd",
   "metadata": {},
   "source": [
    "# Analysis of Synthetic Data\n",
    "\n",
    "This notebook demonstrates a hypothetical scenario of how likely a programmer should be given access to a GPT2 model for inferencing, based on information such as their favorite programming language, preference for tabs vs spaces, OS, location and so forth. Each programmer will be given a score between [0,10] where a score between [7,10] indicates access given to the programmer and [0,7) indicates access denied. The data were synthetically generated via the [PyPI package, Fibber.io](https://pypi.org/project/fibber/).\n",
    "\n",
    "First, we need to specify the version of the RAI components which are available in the workspace. This was specified when the components were uploaded, and will have defaulted to '1':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "53b4eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_string = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06008690",
   "metadata": {},
   "source": [
    "We also need to give the name of the compute cluster we want to use in AzureML. Later in this notebook, we will create it if it does not already exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f1ad79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_name = \"cpucluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc65dc7",
   "metadata": {},
   "source": [
    "Finally, we need to specify a version for the data and components we will create while running this notebook. This should be unique for the workspace, but the specific value doesn't matter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "78053935",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_parkinsons_example_version_string = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be2b63",
   "metadata": {},
   "source": [
    "## Accessing the Data\n",
    "\n",
    "We supply the synthetic data as a pair of parquet files and accompanying `MLTable` file. We can read them in and take a brief look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5f875f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d53df4",
   "metadata": {},
   "source": [
    "Now define the paths to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4c7bbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only necessary first time\n",
    "train_data_path = 'data-parkinsons-regression/train/parkinsons_updrs.train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8c4eb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only necessary first time\n",
    "test_data_path = 'data-parkinsons-regression/test/parkinsons_updrs.test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d2051f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': ['./task_train.parquet'], 'type': 'mltable', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'concrete_train_data', 'description': 'RAI task training data for concrete dataset', 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\hawestra\\\\RAI-vNext-Preview\\\\bugbash\\\\bugbash', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000021606C58190>, 'version': '1', 'latest_version': None, 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/f49d2eeebf890d79f3aed9af1d543a09/train', 'datastore': None})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only necessary first time\n",
    "train_data_pq = pd.read_csv(train_data_path, skipinitialspace=True)   # update here \n",
    "test_data_pq = pd.read_csv(test_data_path, skipinitialspace=True)   # update here \n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4ebb4",
   "metadata": {},
   "source": [
    "Load some data for a quick view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1027fa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>316.1</td>\n",
       "      <td>210.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>689.3</td>\n",
       "      <td>7</td>\n",
       "      <td>24.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>186.2</td>\n",
       "      <td>124.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1083.4</td>\n",
       "      <td>764.3</td>\n",
       "      <td>28</td>\n",
       "      <td>17.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>170.3</td>\n",
       "      <td>155.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1026.6</td>\n",
       "      <td>724.3</td>\n",
       "      <td>7</td>\n",
       "      <td>10.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>272.8</td>\n",
       "      <td>181.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>714.3</td>\n",
       "      <td>28</td>\n",
       "      <td>31.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>339.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                        540.0   \n",
       "1                                        540.0   \n",
       "2                                        332.5   \n",
       "3                                        332.5   \n",
       "4                                        198.6   \n",
       "..                                         ...   \n",
       "594                                      316.1   \n",
       "595                                      186.2   \n",
       "596                                      170.3   \n",
       "597                                      272.8   \n",
       "598                                      339.0   \n",
       "\n",
       "     Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                  0.0       \n",
       "1                                                  0.0       \n",
       "2                                                142.5       \n",
       "3                                                142.5       \n",
       "4                                                132.4       \n",
       "..                                                 ...       \n",
       "594                                              210.7       \n",
       "595                                              124.1       \n",
       "596                                              155.5       \n",
       "597                                              181.9       \n",
       "598                                                0.0       \n",
       "\n",
       "     Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "..                                          ...   \n",
       "594                                         0.0   \n",
       "595                                         0.0   \n",
       "596                                         0.0   \n",
       "597                                         0.0   \n",
       "598                                         0.0   \n",
       "\n",
       "     Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                        162.0   \n",
       "1                                        162.0   \n",
       "2                                        228.0   \n",
       "3                                        228.0   \n",
       "4                                        192.0   \n",
       "..                                         ...   \n",
       "594                                      185.7   \n",
       "595                                      185.7   \n",
       "596                                      185.7   \n",
       "597                                      185.7   \n",
       "598                                      197.0   \n",
       "\n",
       "     Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                  2.5     \n",
       "1                                                  2.5     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "594                                                0.0     \n",
       "595                                                0.0     \n",
       "596                                                0.0     \n",
       "597                                                0.0     \n",
       "598                                                0.0     \n",
       "\n",
       "     Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                               1040.0      \n",
       "1                                               1055.0      \n",
       "2                                                932.0      \n",
       "3                                                932.0      \n",
       "4                                                978.4      \n",
       "..                                                 ...      \n",
       "594                                              977.0      \n",
       "595                                             1083.4      \n",
       "596                                             1026.6      \n",
       "597                                             1012.4      \n",
       "598                                              968.0      \n",
       "\n",
       "     Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                                676.0         28   \n",
       "1                                                676.0         28   \n",
       "2                                                594.0        270   \n",
       "3                                                594.0        365   \n",
       "4                                                825.5        360   \n",
       "..                                                 ...        ...   \n",
       "594                                              689.3          7   \n",
       "595                                              764.3         28   \n",
       "596                                              724.3          7   \n",
       "597                                              714.3         28   \n",
       "598                                              781.0          3   \n",
       "\n",
       "     Concrete compressive strength(MPa, megapascals)  \n",
       "0                                              79.99  \n",
       "1                                              61.89  \n",
       "2                                              40.27  \n",
       "3                                              41.05  \n",
       "4                                              44.30  \n",
       "..                                               ...  \n",
       "594                                            24.44  \n",
       "595                                            17.60  \n",
       "596                                            10.73  \n",
       "597                                            31.38  \n",
       "598                                            13.22  \n",
       "\n",
       "[599 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mltable\n",
    "\n",
    "\n",
    "train_data_path = 'data-parkinsons-regression/train'\n",
    "tbl = mltable.load(train_data_path)\n",
    "train_df: pd.DataFrame = tbl.to_pandas_dataframe()\n",
    "\n",
    "display(train_df)\n",
    "\n",
    "test_data_path = 'data-parkinsons-regression/test'\n",
    "tbl = mltable.load(test_data_path)\n",
    "test_df: pd.DataFrame = tbl.to_pandas_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115ac59",
   "metadata": {},
   "source": [
    "The (synthetic) data are about a collection of parkinsons data, with a 'total_updrs' column which we wish to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5b42df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = f\"'total_UPDRS'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e79b04",
   "metadata": {},
   "source": [
    "First, we need to upload the datasets to our workspace. We start by creating an `MLClient` for interactions with AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "395435fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\hawestra\\RAI-vNext-Preview\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "registry_name = \"azureml\"\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(\n",
    "        credential=credential,\n",
    "        logging_enable=True)\n",
    "\n",
    "ml_client_registry = MLClient(\n",
    "        credential=credential,\n",
    "        subscription_id=ml_client.subscription_id,\n",
    "        resource_group_name=ml_client.resource_group_name,\n",
    "        registry_name=registry_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2d75",
   "metadata": {},
   "source": [
    "#### Convert the train and test files to parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b501735",
   "metadata": {},
   "source": [
    "We can now upload the data to AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "62eb02a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to download MLTable metadata jsonschema from \"None\", skipping validation\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\operations\\_data_operations.py\", line 276, in _try_get_mltable_metadata_jsonschema\n",
      "    return download_mltable_metadata_schema(mltable_schema_url, self._requests_pipeline)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\_utils\\_data_utils.py\", line 30, in download_mltable_metadata_schema\n",
      "    response = requests_pipeline.get(mltable_schema_url)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\_utils\\_http_utils.py\", line 63, in decorated\n",
      "    return self.run(request, **kwargs).http_response\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 211, in run\n",
      "    return first_node.send(pipeline_request)  # type: ignore\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py\", line 158, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py\", line 468, in send\n",
      "    raise err\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py\", line 446, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 103, in send\n",
      "    self._sender.send(request.http_request, **request.context.options),\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 361, in send\n",
      "    raise error\n",
      "azure.core.exceptions.ServiceRequestError: Invalid URL 'None': No scheme supplied. Perhaps you meant http://None?\n",
      "Failed to download MLTable metadata jsonschema from \"None\", skipping validation\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\operations\\_data_operations.py\", line 276, in _try_get_mltable_metadata_jsonschema\n",
      "    return download_mltable_metadata_schema(mltable_schema_url, self._requests_pipeline)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\_utils\\_data_utils.py\", line 30, in download_mltable_metadata_schema\n",
      "    response = requests_pipeline.get(mltable_schema_url)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\_utils\\_http_utils.py\", line 63, in decorated\n",
      "    return self.run(request, **kwargs).http_response\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 211, in run\n",
      "    return first_node.send(pipeline_request)  # type: ignore\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py\", line 158, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py\", line 468, in send\n",
      "    raise err\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py\", line 446, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 103, in send\n",
      "    self._sender.send(request.http_request, **request.context.options),\n",
      "  File \"c:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 361, in send\n",
      "    raise error\n",
      "azure.core.exceptions.ServiceRequestError: Invalid URL 'None': No scheme supplied. Perhaps you meant http://None?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': ['./task_test.parquet'], 'type': 'mltable', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'concrete_test_data_final', 'description': 'RAI task test data for concrete dataset ', 'tags': {}, 'properties': {}, 'id': '/subscriptions/2d385bf4-0756-4a76-aa95-28bf9ed3b625/resourceGroups/hawestra-rg/providers/Microsoft.MachineLearningServices/workspaces/hawestra_myws/data/concrete_test_data_final/versions/1', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\hawestra\\\\RAI-vNext-Preview\\\\bugbash\\\\bugbash', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x00000216069F3DF0>, 'serialize': <msrest.serialization.Serializer object at 0x0000021606C1A6D0>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/2d385bf4-0756-4a76-aa95-28bf9ed3b625/resourcegroups/hawestra-rg/workspaces/hawestra_myws/datastores/workspaceblobstore/paths/LocalUpload/dc7d99c2c3ea32b5f90796002ef3e6e2/test/', 'datastore': None})"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "input_train_data = \"parkinsons_train_data\"  # update here\n",
    "input_test_data = \"parkinsons_test_data_final\"  # update here\n",
    "\n",
    "train_data = Data(\n",
    "    path=train_data_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description=\"RAI task training data for parkinsons dataset\",\n",
    "    name=input_train_data,\n",
    "    version=rai_parkinsons_example_version_string,\n",
    ")\n",
    "ml_client.data.create_or_update(train_data)\n",
    "\n",
    "test_data = Data(\n",
    "    path=test_data_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description=\"RAI task test data for parkinsons dataset \",\n",
    "    name=input_test_data,\n",
    "    version=rai_parkinsons_example_version_string,\n",
    ")\n",
    "ml_client.data.create_or_update(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815ba75",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "\n",
    "To simplify the model creation process, we're going to use a pipeline.\n",
    "\n",
    "We create a directory for the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e78d869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('register_model_src', exist_ok=True)\n",
    "os.makedirs('programmer_component_src', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86e55d",
   "metadata": {},
   "source": [
    "Next, we write out our training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a523f144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting programmer_component_src/training_script_reg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile programmer_component_src/training_script_reg.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import mltable\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\n",
    "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\n",
    "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "def create_regression_pipeline(X, y):\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    pipeline = Pipeline(steps=[('preprocessor', feat_pipe),\n",
    "                               ('model', LinearRegression())])\n",
    "    return pipeline.fit(X, y)\n",
    "\n",
    "def main(args):\n",
    "    current_experiment = Run.get_context().experiment\n",
    "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\n",
    "    print(\"tracking_uri: {0}\".format(tracking_uri))\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(current_experiment.name)\n",
    "    \n",
    "    # Read in data\n",
    "    print(\"Reading data\")\n",
    "    tbl = mltable.load(args.training_data)\n",
    "    all_data = tbl.to_pandas_dataframe()\n",
    "\n",
    "    print(\"Extracting X_train, y_train\")\n",
    "    print(\"all_data cols: {0}\".format(all_data.columns))\n",
    "    y_train = all_data[args.target_column_name]\n",
    "    X_train = all_data.drop(labels=args.target_column_name, axis=\"columns\")\n",
    "    print(\"X_train cols: {0}\".format(X_train.columns))\n",
    "\n",
    "    print(\"Training model\")\n",
    "    # The estimator can be changed to suit\n",
    "    model = create_regression_pipeline(X_train, y_train)\n",
    "\n",
    "    # Saving model with mlflow - leave this section unchanged\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        print(\"Saving model with MLFlow to temporary directory\")\n",
    "        tmp_output_dir = os.path.join(td, \"my_model_dir\")\n",
    "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\n",
    "\n",
    "        print(\"Copying MLFlow model to output path\")\n",
    "        for file_name in os.listdir(tmp_output_dir):\n",
    "            print(\"  Copying: \", file_name)\n",
    "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\n",
    "            # an option, removing the need for listdir\n",
    "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "65af35fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting register_model_src/register.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile register_model_src/register.py\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Based on example:\n",
    "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-cli\n",
    "# which references\n",
    "# https://github.com/Azure/azureml-examples/tree/main/cli/jobs/train/lightgbm/iris\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--model_input_path\", type=str, help=\"Path to input model\")\n",
    "    parser.add_argument(\n",
    "        \"--model_info_output_path\", type=str, help=\"Path to write model info JSON\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_base_name\", type=str, help=\"Name of the registered model\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name_suffix\", type=int, help=\"Set negative to use epoch_secs\"\n",
    "    )\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    current_experiment = Run.get_context().experiment\n",
    "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\n",
    "    print(\"tracking_uri: {0}\".format(tracking_uri))\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(current_experiment.name)\n",
    "\n",
    "    print(\"Loading model\")\n",
    "    mlflow_model = mlflow.sklearn.load_model(args.model_input_path)\n",
    "\n",
    "    if args.model_name_suffix < 0:\n",
    "        suffix = int(time.time())\n",
    "    else:\n",
    "        suffix = args.model_name_suffix\n",
    "    registered_name = \"{0}_{1}\".format(args.model_base_name, suffix)\n",
    "    print(f\"Registering model as {registered_name}\")\n",
    "\n",
    "    print(\"Registering via MLFlow\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=mlflow_model,\n",
    "        registered_model_name=registered_name,\n",
    "        artifact_path=registered_name,\n",
    "    )\n",
    "\n",
    "    print(\"Writing JSON\")\n",
    "    dict = {\"id\": \"{0}:1\".format(registered_name)}\n",
    "    output_path = os.path.join(args.model_info_output_path, \"model_info.json\")\n",
    "    with open(output_path, \"w\") as of:\n",
    "        json.dump(dict, fp=of)\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115dd6e",
   "metadata": {},
   "source": [
    "Now, we can build this into an AzureML component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3d54e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_component\n",
    "\n",
    "yaml_contents = f\"\"\"\n",
    "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
    "name: rai_concrete_training_component\n",
    "display_name: Parkinsons training component for RAI example\n",
    "version: {rai_parkinsons_example_version_string}\n",
    "type: command\n",
    "inputs:\n",
    "  training_data:\n",
    "    type: path\n",
    "  target_column_name:\n",
    "    type: string\n",
    "outputs:\n",
    "  model_output:\n",
    "    type: path\n",
    "code: ./programmer_component_src/\n",
    "environment: azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4\n",
    "command: >-\n",
    "  python training_script_reg.py\n",
    "  --training_data ${{{{inputs.training_data}}}}\n",
    "  --target_column_name ${{{{inputs.target_column_name}}}}\n",
    "  --model_output ${{{{outputs.model_output}}}}\n",
    "\"\"\"\n",
    "\n",
    "yaml_filename = \"ProgrammersRegTrainingComp.yaml\"\n",
    "\n",
    "with open(yaml_filename, 'w') as f:\n",
    "    f.write(yaml_contents)\n",
    "    \n",
    "train_model_component = load_component(\n",
    "    source=yaml_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "f9cde33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_contents = f\"\"\"\n",
    "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
    "name: register_model\n",
    "display_name: Register Model\n",
    "version: {rai_parkinsons_example_version_string}\n",
    "type: command\n",
    "is_deterministic: False\n",
    "inputs:\n",
    "  model_input_path:\n",
    "    type: path\n",
    "  model_base_name:\n",
    "    type: string\n",
    "  model_name_suffix: # Set negative to use epoch_secs\n",
    "    type: integer\n",
    "    default: -1\n",
    "outputs:\n",
    "  model_info_output_path:\n",
    "    type: path\n",
    "code: ./register_model_src/\n",
    "environment: azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4\n",
    "command: >-\n",
    "  python register.py\n",
    "  --model_input_path ${{{{inputs.model_input_path}}}}\n",
    "  --model_base_name ${{{{inputs.model_base_name}}}}\n",
    "  --model_name_suffix ${{{{inputs.model_name_suffix}}}}\n",
    "  --model_info_output_path ${{{{outputs.model_info_output_path}}}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "yaml_filename = \"register.yaml\"\n",
    "\n",
    "with open(yaml_filename, 'w') as f:\n",
    "    f.write(yaml_contents)\n",
    "    \n",
    "register_component = load_component(\n",
    "    source=yaml_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d165e2b",
   "metadata": {},
   "source": [
    "We need a compute target on which to run our jobs. The following checks whether the compute specified above is present; if not, then the compute target is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1e40fc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute: cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "all_compute_names = [x.name for x in ml_client.compute.list()]\n",
    "\n",
    "if compute_name in all_compute_names:\n",
    "    print(f\"Found existing compute: {compute_name}\")\n",
    "else:\n",
    "    my_compute = AmlCompute(\n",
    "        name=compute_name,\n",
    "        size=\"Standard_DS4_v2\",\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        idle_time_before_scale_down=3600\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(my_compute)\n",
    "    print(\"Initiated compute creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8eb868",
   "metadata": {},
   "source": [
    "## Running a training pipeline\n",
    "\n",
    "Now that we have our training component, we can run it. We begin by generating a unique name for the mode;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ad76242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_name_suffix = int(time.time())\n",
    "model_name = 'rai_programmer_example_reg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49615a7",
   "metadata": {},
   "source": [
    "Next, we define our training pipeline. This has two components. The first is the training component which we defined above. The second is a component to register the model in AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "cb6c6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input\n",
    "\n",
    "\n",
    "parkinsons_train_mltable = Input(\n",
    "    type=\"mltable\", path=f\"azureml:{input_train_data}:1\", mode=\"download\"\n",
    ")\n",
    "parkinsons_test_mltable = Input(\n",
    "    type=\"mltable\", path=f\"azureml:{input_test_data}:1\", mode=\"download\"\n",
    ")\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=compute_name,\n",
    "    description=\"Register Model for RAI parkinsons example\",\n",
    "    experiment_name=f\"RAI_Parkinsons_Example_Model_Training_{model_name_suffix}\",\n",
    ")\n",
    "def my_training_pipeline(target_column_name, training_data):\n",
    "    trained_model = train_model_component(\n",
    "        target_column_name=target_column_name,\n",
    "        training_data=training_data\n",
    "    )\n",
    "    trained_model.set_limits(timeout=120)\n",
    "\n",
    "    _ = register_component(\n",
    "        model_input_path=trained_model.outputs.model_output,\n",
    "        model_base_name=model_name,\n",
    "        model_name_suffix=model_name_suffix,\n",
    "    )\n",
    "\n",
    "    return {}\n",
    "\n",
    "model_registration_pipeline_job = my_training_pipeline(target_column_name, parkinsons_train_mltable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa66ea6",
   "metadata": {},
   "source": [
    "With the training pipeline defined, we can submit it for execution in AzureML. We define a helper function to wait for the job to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f854eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline job can be accessed in the following URL:\n",
      "https://ml.azure.com/runs/ivory_dog_zjbsfg4l3t?wsid=/subscriptions/2d385bf4-0756-4a76-aa95-28bf9ed3b625/resourcegroups/hawestra-rg/workspaces/hawestra_myws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import PipelineJob\n",
    "\n",
    "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
    "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    assert created_job is not None\n",
    "\n",
    "    print(\"Pipeline job can be accessed in the following URL:\")\n",
    "    print(f'{created_job.studio_url}')\n",
    "\n",
    "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\n",
    "        time.sleep(30)\n",
    "        created_job = ml_client.jobs.get(created_job.name)\n",
    "        print(\"Latest status : {0}\".format(created_job.status))\n",
    "    assert created_job.status == 'Completed'\n",
    "    return created_job\n",
    "\n",
    "# This is the actual submission\n",
    "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722395e",
   "metadata": {},
   "source": [
    "## Creating the RAI Insights\n",
    "\n",
    "Now that we have our model, we can generate RAI insights for it. We will need the `id` of the registered model, which will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7d3e6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_id = f'{model_name}_{model_name_suffix}:1'\n",
    "azureml_model_id = f'azureml:{expected_model_id}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310aa659",
   "metadata": {},
   "source": [
    "Next, we load the RAI components, so that we can construct a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d67b942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"latest\"\n",
    "\n",
    "rai_constructor_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\n",
    ")\n",
    "\n",
    "# We get latest version and use the same version for all components\n",
    "version = rai_constructor_component.version\n",
    "\n",
    "rai_explanation_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\n",
    ")\n",
    "\n",
    "rai_causal_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_causal\", version=version\n",
    ")\n",
    "\n",
    "rai_counterfactual_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_counterfactual\", version=version\n",
    ")\n",
    "\n",
    "rai_erroranalysis_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\n",
    ")\n",
    "\n",
    "rai_gather_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\n",
    ")\n",
    "\n",
    "rai_scorecard_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_score_card\", version=version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b22cd",
   "metadata": {},
   "source": [
    "## Score card generation config\n",
    "For score card generation, we need some additional configuration in a separate json file. Here we configure the following model performance metrics for reporting:\n",
    "- mean absolute error\n",
    "- mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "872e1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "TODO\n",
    "score_card_config_dict = {\n",
    "  \"Model\": {\n",
    "    \"ModelName\": \"GPT2 Access\",\n",
    "    \"ModelType\": \"Regression\",\n",
    "    \"ModelSummary\": \"This is a regression model to analyze concrete data\"\n",
    "  },\n",
    "  \"Metrics\": {\n",
    "    \"mean_absolute_error\": {},\n",
    "    \"mean_squared_error\": {}\n",
    "  },\n",
    "  \"FeatureImportance\": {\n",
    "    \"top_n\": 4\n",
    "  },\n",
    "  \"DataExplorer\": {\n",
    "    \"features\": []\n",
    "  },\n",
    "  \"Fairness\": {\n",
    "    \"metric\": [\"mean_squared_error\", \"mean_absolute_error\"],\n",
    "    \"sensitive_features\": [],\n",
    "    \"fairness_evaluation_kind\": \"difference\"\n",
    "  }\n",
    "}\n",
    "\n",
    "score_card_config_filename = \"rai_programmer_regression_score_card_config.json\"\n",
    "\n",
    "with open(score_card_config_filename, 'w') as f:\n",
    "    json.dump(score_card_config_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cd2d9",
   "metadata": {},
   "source": [
    "We can now specify our pipeline. Complex objects (such as lists of column names) have to be converted to JSON strings before being passed to the components. Note that the timeout for the counterfactual job is noticeably longer, since generating counterfactual points is a comparatively slow process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a62105a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "score_card_config_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=score_card_config_filename,\n",
    "    mode=\"download\"\n",
    ")\n",
    "\n",
    "categorical_columns = json.dumps([])\n",
    "treatment_features = json.dumps([\"Age (day)\"])\n",
    "desired_range = json.dumps([5, 40])\n",
    "filter_columns = json.dumps([\"Cement (component 1)(kg in a m^3 mixture)\", \"Water  (component 4)(kg in a m^3 mixture)\"])\n",
    "\n",
    "@dsl.pipeline(\n",
    "        compute=compute_name,\n",
    "        description=\"Example RAI computation on concrete data\",\n",
    "        experiment_name=f\"RAI_Concrete_Example_RAIInsights_Computation_{model_name_suffix}\",\n",
    "    )\n",
    "def rai_programmer_regression_pipeline(\n",
    "        target_column_name,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        score_card_config_path,\n",
    "    ):\n",
    "        # Initiate the RAIInsights\n",
    "        create_rai_job = rai_constructor_component(\n",
    "            title=\"RAI Dashboard Example\",\n",
    "            task_type=\"regression\",\n",
    "            model_info=expected_model_id,\n",
    "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n",
    "            train_dataset=train_data,\n",
    "            test_dataset=test_data,\n",
    "            target_column_name=target_column_name,\n",
    "            categorical_column_names=categorical_columns\n",
    "        )\n",
    "        create_rai_job.set_limits(timeout=120)\n",
    "        \n",
    "        # Add an explanation\n",
    "        explain_job = rai_explanation_component(\n",
    "            comment=\"Explanation for the concrete dataset\",\n",
    "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "        )\n",
    "        explain_job.set_limits(timeout=120)\n",
    "        \n",
    "        # Add causal analysis\n",
    "        causal_job = rai_causal_component(\n",
    "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "            treatment_features=treatment_features,\n",
    "        )\n",
    "        causal_job.set_limits(timeout=180)\n",
    "        \n",
    "        # Add counterfactual analysis\n",
    "        counterfactual_job = rai_counterfactual_component(\n",
    "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "            total_cfs=10,\n",
    "            desired_range=desired_range\n",
    "        )\n",
    "        counterfactual_job.set_limits(timeout=600)\n",
    "        \n",
    "        # Add error analysis\n",
    "        erroranalysis_job = rai_erroranalysis_component(\n",
    "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "            filter_features=filter_columns\n",
    "        )\n",
    "        erroranalysis_job.set_limits(timeout=120)\n",
    "        \n",
    "        # Combine everything\n",
    "        rai_gather_job = rai_gather_component(\n",
    "            constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
    "            insight_1=explain_job.outputs.explanation,\n",
    "            insight_2=causal_job.outputs.causal,\n",
    "            insight_3=counterfactual_job.outputs.counterfactual,\n",
    "            insight_4=erroranalysis_job.outputs.error_analysis,\n",
    "        )\n",
    "        rai_gather_job.set_limits(timeout=120)\n",
    "\n",
    "        rai_gather_job.outputs.dashboard.mode = \"upload\"\n",
    "        rai_gather_job.outputs.ux_json.mode = \"upload\"\n",
    "\n",
    "        # Generate score card in pdf format for a summary report on model performance,\n",
    "        # and observe distrbution of error between prediction vs ground truth.\n",
    "        rai_scorecard_job = rai_scorecard_component(\n",
    "            dashboard=rai_gather_job.outputs.dashboard,\n",
    "            pdf_generation_config=score_card_config_path\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"dashboard\": rai_gather_job.outputs.dashboard,\n",
    "            \"ux_json\": rai_gather_job.outputs.ux_json,\n",
    "            \"scorecard\": rai_scorecard_job.outputs.scorecard\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b14a9",
   "metadata": {},
   "source": [
    "Next, we define the pipeline object itself, and ensure that the outputs will be available for download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e4d86ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from azure.ai.ml import Output\n",
    "\n",
    "insights_pipeline_job = rai_programmer_regression_pipeline(\n",
    "    target_column_name=target_column_name,\n",
    "    train_data=concrete_train_mltable,\n",
    "    test_data=concrete_test_mltable,\n",
    "    score_card_config_path=score_card_config_path,\n",
    ")\n",
    "\n",
    "rand_path = str(uuid.uuid4())\n",
    "insights_pipeline_job.outputs.dashboard = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\",\n",
    ")\n",
    "insights_pipeline_job.outputs.ux_json = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\",\n",
    ")\n",
    "insights_pipeline_job.outputs.scorecard = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/scorecard/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f34573",
   "metadata": {},
   "source": [
    "And submit the pipeline to AzureML for execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2ca757f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline job can be accessed in the following URL:\n",
      "https://ml.azure.com/runs/busy_napkin_87z8cgtwsb?wsid=/subscriptions/2d385bf4-0756-4a76-aa95-28bf9ed3b625/resourcegroups/hawestra-rg/workspaces/hawestra_myws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381768a",
   "metadata": {},
   "source": [
    "The dashboard should appear in the AzureML portal in the registered model view. The following cell computes the expected URI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e86ab611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit https://ml.azure.com/model/rai_programmer_example_reg_1666388603:1/model_analysis?wsid=/subscriptions/2d385bf4-0756-4a76-aa95-28bf9ed3b625/resourcegroups/hawestra-rg/workspaces/hawestra_myws to see your analysis\n"
     ]
    }
   ],
   "source": [
    "sub_id = ml_client._operation_scope.subscription_id\n",
    "rg_name = ml_client._operation_scope.resource_group_name\n",
    "ws_name = ml_client.workspace_name\n",
    "\n",
    "expected_uri = f\"https://ml.azure.com/model/{expected_model_id}/model_analysis?wsid=/subscriptions/{sub_id}/resourcegroups/{rg_name}/workspaces/{ws_name}\"\n",
    "\n",
    "print(f\"Please visit {expected_uri} to see your analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513d61c",
   "metadata": {},
   "source": [
    "## Downloading the Scorecard PDF\n",
    "\n",
    "We can download the scorecard PDF from our pipeline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "55e1350c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceResponseError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServiceResponseError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hawestra\\RAI-vNext-Preview\\bugbash\\bugbash\\responsibleaidashboard-programmer-regression-model-debugging.ipynb Cell 53\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hawestra/RAI-vNext-Preview/bugbash/bugbash/responsibleaidashboard-programmer-regression-model-debugging.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m target_directory \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hawestra/RAI-vNext-Preview/bugbash/bugbash/responsibleaidashboard-programmer-regression-model-debugging.ipynb#Y101sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mdownload(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hawestra/RAI-vNext-Preview/bugbash/bugbash/responsibleaidashboard-programmer-regression-model-debugging.ipynb#Y101sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     insights_job\u001b[39m.\u001b[39;49mname, download_path\u001b[39m=\u001b[39;49mtarget_directory, output_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mscorecard\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hawestra/RAI-vNext-Preview/bugbash/bugbash/responsibleaidashboard-programmer-regression-model-debugging.ipynb#Y101sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:704\u001b[0m, in \u001b[0;36mJobOperations.download\u001b[1;34m(self, name, download_path, output_name, all)\u001b[0m\n\u001b[0;32m    702\u001b[0m         log_missing_uri(\u001b[39m\"\u001b[39m\u001b[39mbatch job scoring file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    703\u001b[0m \u001b[39melif\u001b[39;00m output_name:\n\u001b[1;32m--> 704\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_named_output_uri(name, output_name)\n\u001b[0;32m    706\u001b[0m     \u001b[39mif\u001b[39;00m output_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m outputs:\n\u001b[0;32m    707\u001b[0m         log_missing_uri(what\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00moutput_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:753\u001b[0m, in \u001b[0;36mJobOperations._get_named_output_uri\u001b[1;34m(self, job_name, output_names)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[39melif\u001b[39;00m output_names:\n\u001b[0;32m    751\u001b[0m     output_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(output_names)\n\u001b[1;32m--> 753\u001b[0m outputs \u001b[39m=\u001b[39m get_job_output_uris_from_dataplane(\n\u001b[0;32m    754\u001b[0m     job_name,\n\u001b[0;32m    755\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runs_operations,\n\u001b[0;32m    756\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_dataplane_operations,\n\u001b[0;32m    757\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_dataplane_operations,\n\u001b[0;32m    758\u001b[0m     output_names\u001b[39m=\u001b[39;49moutput_names,\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    761\u001b[0m missing_outputs \u001b[39m=\u001b[39m (output_names \u001b[39mor\u001b[39;00m \u001b[39mset\u001b[39m())\u001b[39m.\u001b[39mdifference(outputs\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m    763\u001b[0m \u001b[39m# Include default artifact store in outputs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_ops_helper.py:413\u001b[0m, in \u001b[0;36mget_job_output_uris_from_dataplane\u001b[1;34m(job_name, run_operations, dataset_dataplane_operations, model_dataplane_operations, output_names)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_job_output_uris_from_dataplane\u001b[39m(\n\u001b[0;32m    397\u001b[0m     job_name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    398\u001b[0m     run_operations: RunOperations,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    401\u001b[0m     output_names: Optional[Union[Iterable[\u001b[39mstr\u001b[39m], \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    402\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    403\u001b[0m     \u001b[39m\"\"\"Returns the output path for the given output in cloud storage of the\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39m    given job.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39m    :rtype: Dict[str, str]\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m     run_metadata: Run \u001b[39m=\u001b[39m run_operations\u001b[39m.\u001b[39;49mget_run_data(job_name)\u001b[39m.\u001b[39mrun_metadata\n\u001b[0;32m    414\u001b[0m     run_outputs: Dict[\u001b[39mstr\u001b[39m, TypedAssetReference] \u001b[39m=\u001b[39m run_metadata\u001b[39m.\u001b[39moutputs \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m    416\u001b[0m     \u001b[39m# Create a reverse mapping from internal asset id to user-defined output name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\operations\\_run_operations.py:79\u001b[0m, in \u001b[0;36mRunOperations.get_run_data\u001b[1;34m(self, run_id)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_run_data\u001b[39m(\u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m GetRunDataResult:\n\u001b[0;32m     73\u001b[0m     run_data_request \u001b[39m=\u001b[39m GetRunDataRequest(\n\u001b[0;32m     74\u001b[0m         run_id\u001b[39m=\u001b[39mrun_id,\n\u001b[0;32m     75\u001b[0m         select_run_metadata\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m         select_run_definition\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m         select_job_specification\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     78\u001b[0m     )\n\u001b[1;32m---> 79\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation\u001b[39m.\u001b[39;49mget_run_data(\n\u001b[0;32m     80\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_subscription_id,\n\u001b[0;32m     81\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resource_group_name,\n\u001b[0;32m     82\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_workspace_name,\n\u001b[0;32m     83\u001b[0m         body\u001b[39m=\u001b[39;49mrun_data_request,\n\u001b[0;32m     84\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\ai\\ml\\_restclient\\runhistory\\operations\\_runs_operations.py:1944\u001b[0m, in \u001b[0;36mRunsOperations.get_run_data\u001b[1;34m(self, subscription_id, resource_group_name, workspace_name, body, **kwargs)\u001b[0m\n\u001b[0;32m   1941\u001b[0m request \u001b[39m=\u001b[39m _convert_request(request)\n\u001b[0;32m   1942\u001b[0m request\u001b[39m.\u001b[39murl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mformat_url(request\u001b[39m.\u001b[39murl)\n\u001b[1;32m-> 1944\u001b[0m pipeline_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_pipeline\u001b[39m.\u001b[39;49mrun(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m   1945\u001b[0m     request,\n\u001b[0;32m   1946\u001b[0m     stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1947\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m   1948\u001b[0m )\n\u001b[0;32m   1949\u001b[0m response \u001b[39m=\u001b[39m pipeline_response\u001b[39m.\u001b[39mhttp_response\n\u001b[0;32m   1951\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:211\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m pipeline_request \u001b[39m=\u001b[39m PipelineRequest(\n\u001b[0;32m    204\u001b[0m     request, context\n\u001b[0;32m    205\u001b[0m )  \u001b[39m# type: PipelineRequest[HTTPRequestType]\u001b[39;00m\n\u001b[0;32m    206\u001b[0m first_node \u001b[39m=\u001b[39m (\n\u001b[0;32m    207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies[\u001b[39m0\u001b[39m]\n\u001b[0;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m _TransportRunner(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport)\n\u001b[0;32m    210\u001b[0m )\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m first_node\u001b[39m.\u001b[39;49msend(pipeline_request)\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[0;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[0;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "    \u001b[1;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 71 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[0;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\mgmt\\core\\policies\\_base.py:47\u001b[0m, in \u001b[0;36mARMAutoResourceProviderRegistrationPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[0;32m     45\u001b[0m     \u001b[39m# type: (PipelineRequest[HTTPRequestType], Any) -> PipelineResponse[HTTPRequestType, HTTPResponseType]\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     http_request \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mhttp_request\n\u001b[1;32m---> 47\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mhttp_response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m409\u001b[39m:\n\u001b[0;32m     49\u001b[0m         rp_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_rp_not_registered_err(response)\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py:158\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    156\u001b[0m redirect_settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfigure_redirects(request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39moptions)\n\u001b[0;32m    157\u001b[0m \u001b[39mwhile\u001b[39;00m retryable:\n\u001b[1;32m--> 158\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m    159\u001b[0m     redirect_location \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_redirect_location(response)\n\u001b[0;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m redirect_location \u001b[39mand\u001b[39;00m redirect_settings[\u001b[39m'\u001b[39m\u001b[39mallow\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py:468\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    466\u001b[0m                 is_response_error \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    467\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 468\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    469\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py:446\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    444\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    445\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[1;32m--> 446\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m    447\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_retry(retry_settings, response):\n\u001b[0;32m    448\u001b[0m     retry_active \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincrement(retry_settings, response\u001b[39m=\u001b[39mresponse)\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py:118\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_request(request)\n\u001b[0;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m    119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_response(request, response)\n\u001b[0;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[0;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[0;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "    \u001b[1;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 71 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[0;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:103\u001b[0m, in \u001b[0;36m_TransportRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[0;32m     94\u001b[0m     \u001b[39m\"\"\"HTTP transport send method.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[39m    :param request: The PipelineRequest object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m    :rtype: ~azure.core.pipeline.PipelineResponse\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m PipelineResponse(\n\u001b[0;32m    102\u001b[0m         request\u001b[39m.\u001b[39mhttp_request,\n\u001b[1;32m--> 103\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sender\u001b[39m.\u001b[39;49msend(request\u001b[39m.\u001b[39;49mhttp_request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrequest\u001b[39m.\u001b[39;49mcontext\u001b[39m.\u001b[39;49moptions),\n\u001b[0;32m    104\u001b[0m         context\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mcontext,\n\u001b[0;32m    105\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hawestra\\Anaconda3\\envs\\raienv\\lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py:361\u001b[0m, in \u001b[0;36mRequestsTransport.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m     error \u001b[39m=\u001b[39m ServiceRequestError(err, error\u001b[39m=\u001b[39merr)\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m error:\n\u001b[1;32m--> 361\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m    362\u001b[0m \u001b[39mif\u001b[39;00m _is_rest(request):\n\u001b[0;32m    363\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrest\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_requests_basic\u001b[39;00m \u001b[39mimport\u001b[39;00m RestRequestsTransportResponse\n",
      "\u001b[1;31mServiceResponseError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "target_directory = \".\"\n",
    "\n",
    "ml_client.jobs.download(\n",
    "    insights_job.name, download_path=target_directory, output_name=\"scorecard\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4088857c97f74d500d4cbc5795c24cebea5e8042225bbf6eac81e70c52647a8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
