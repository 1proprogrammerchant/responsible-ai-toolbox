{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "restricted-republic",
   "metadata": {},
   "source": [
    "# Assess income level predictions on adult census data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-fusion",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of the `responsibleai` API to assess a model trained on census data. It walks through the API calls necessary to create a widget with model analysis insights, then guides a visual analysis of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-cartoon",
   "metadata": {},
   "source": [
    "* [Launch Responsible AI Toolbox](#Launch-Responsible-AI-Toolbox)\n",
    "    * [Train a Model](#Train-a-Model)\n",
    "    * [Create Model and Data Insights](#Create-Model-and-Data-Insights)\n",
    "* [Assess Your Model](#Assess-Your-Model)\n",
    "    * [Aggregate Analysis](#Aggregate-Analysis)\n",
    "    * [Individual Analysis](#Individual-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-dream",
   "metadata": {},
   "source": [
    "## Launch Responsible AI Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-crisis",
   "metadata": {},
   "source": [
    "The following section examines the code necessary to create datasets and a model. It then generates insights using the `responsibleai` API that can be visually analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-bryan",
   "metadata": {},
   "source": [
    "### Train a Model\n",
    "*The following section can be skipped. It loads a dataset and trains a model for illustrative purposes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indie-message",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import zipfile\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-henry",
   "metadata": {},
   "source": [
    "First, load the census dataset and specify the different types of features. Then, clean the target feature values to include only 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resistant-consequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['workclass', 'education', 'marital-status', 'occupation', 'relationship']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def split_label(dataset, target_feature):\n",
    "    X = dataset.drop([target_feature], axis=1)\n",
    "    y = dataset[[target_feature]]\n",
    "    return X, y\n",
    "\n",
    "def clean_data(X, y, target_feature):\n",
    "    features = X.columns.values.tolist()\n",
    "    classes = y[target_feature].unique().tolist()\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "    X = feat_pipe.fit_transform(X)\n",
    "    print(pipe_cfg['cat_cols'])\n",
    "    return X, feat_pipe, features, classes\n",
    "\n",
    "outdirname = 'responsibleai.12.28.21'\n",
    "try:\n",
    "    from urllib import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve\n",
    "zipfilename = outdirname + '.zip'\n",
    "urlretrieve('https://publictestdatasets.blob.core.windows.net/data/' + zipfilename, zipfilename)\n",
    "with zipfile.ZipFile(zipfilename, 'r') as unzip:\n",
    "    unzip.extractall('.')\n",
    "\n",
    "target_feature = 'income'\n",
    "categorical_features = ['workclass', 'education', 'marital-status',\n",
    "                        'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "sensitive_features = ['race', 'gender', 'native-country']\n",
    "\n",
    "train_data = pd.read_csv('adult-train.csv')\n",
    "test_data = pd.read_csv('adult-test.csv')\n",
    "\n",
    "\n",
    "X_train_original, y_train = split_label(train_data, target_feature)\n",
    "X_test_original, y_test = split_label(test_data, target_feature)\n",
    "\n",
    "\n",
    "X_train, feat_pipe, features, classes = clean_data(X_train_original.drop(columns=sensitive_features), y_train, target_feature)\n",
    "y_train = y_train[target_feature].to_numpy()\n",
    "\n",
    "X_test = feat_pipe.transform(X_test_original.drop(columns=sensitive_features))\n",
    "y_test = y_test[target_feature].to_numpy()\n",
    "\n",
    "train_data[target_feature] = y_train\n",
    "test_data[target_feature] = y_test\n",
    "\n",
    "test_data_sample = test_data.sample(n=100, random_state=5)\n",
    "train_data_sample = train_data.sample(n=8000, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-proportion",
   "metadata": {},
   "source": [
    "Train a LightGBM classifier on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "biological-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(n_estimators=5)\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-praise",
   "metadata": {},
   "source": [
    "### Create Model and Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "residential-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "from raiwidgets import ResponsibleAIDashboard\n",
    "from responsibleai import RAIInsights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-juice",
   "metadata": {},
   "source": [
    "To use Responsible AI Toolbox, initialize a RAIInsights object upon which different components can be loaded.\n",
    "\n",
    "RAIInsights accepts the model, the full dataset, the test dataset, the target feature string, the task type string, and a list of strings of categorical feature names as its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bulgarian-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_pipeline = Pipeline(steps=[('preprocess', feat_pipe), ('model', model)])\n",
    "\n",
    "rai_insights = RAIInsights(dashboard_pipeline, train_data_sample, test_data_sample, target_feature, 'classification',\n",
    "                               categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-rolling",
   "metadata": {},
   "source": [
    "Add the components of the toolbox that are focused on model assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "governing-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretability\n",
    "rai_insights.explainer.add()\n",
    "# Error Analysis\n",
    "rai_insights.error_analysis.add()\n",
    "# Counterfactuals: accepts total number of counterfactuals to generate, the label that they should have, and a list of \n",
    "                # strings of categorical feature names\n",
    "rai_insights.counterfactual.add(total_CFs=10, desired_class='opposite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-bicycle",
   "metadata": {},
   "source": [
    "Once all the desired components have been loaded, compute insights on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "average-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  1%|          | 1/100 [00:01<02:34,  1.56s/it]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  2%|▏         | 2/100 [00:01<01:21,  1.20it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  3%|▎         | 3/100 [00:02<00:58,  1.67it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  4%|▍         | 4/100 [00:02<00:46,  2.07it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  5%|▌         | 5/100 [00:02<00:40,  2.35it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  6%|▌         | 6/100 [00:03<00:36,  2.60it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  7%|▋         | 7/100 [00:03<00:33,  2.77it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  8%|▊         | 8/100 [00:03<00:33,  2.75it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  9%|▉         | 9/100 [00:04<00:38,  2.37it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 10%|█         | 10/100 [00:04<00:40,  2.23it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 11%|█         | 11/100 [00:05<00:40,  2.19it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 12%|█▏        | 12/100 [00:05<00:39,  2.24it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 13%|█▎        | 13/100 [00:06<00:38,  2.27it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 14%|█▍        | 14/100 [00:06<00:38,  2.24it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 15%|█▌        | 15/100 [00:07<00:38,  2.23it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 16%|█▌        | 16/100 [00:07<00:37,  2.24it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 17%|█▋        | 17/100 [00:08<00:37,  2.19it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 18%|█▊        | 18/100 [00:08<00:36,  2.24it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 19%|█▉        | 19/100 [00:08<00:35,  2.28it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 20%|██        | 20/100 [00:09<00:37,  2.13it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 21%|██        | 21/100 [00:09<00:36,  2.15it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 22%|██▏       | 22/100 [00:10<00:43,  1.80it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 23%|██▎       | 23/100 [00:11<00:41,  1.88it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 24%|██▍       | 24/100 [00:11<00:40,  1.90it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 25%|██▌       | 25/100 [00:12<00:43,  1.73it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 26%|██▌       | 26/100 [00:12<00:41,  1.79it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 27%|██▋       | 27/100 [00:13<00:39,  1.83it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 28%|██▊       | 28/100 [00:13<00:39,  1.84it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 29%|██▉       | 29/100 [00:14<00:37,  1.90it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 30%|███       | 30/100 [00:14<00:35,  1.99it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 31%|███       | 31/100 [00:15<00:32,  2.09it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 32%|███▏      | 32/100 [00:15<00:31,  2.19it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 33%|███▎      | 33/100 [00:16<00:29,  2.25it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 34%|███▍      | 34/100 [00:16<00:29,  2.27it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 35%|███▌      | 35/100 [00:16<00:28,  2.26it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 36%|███▌      | 36/100 [00:17<00:28,  2.27it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 37%|███▋      | 37/100 [00:17<00:26,  2.35it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 38%|███▊      | 38/100 [00:18<00:26,  2.33it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 39%|███▉      | 39/100 [00:18<00:25,  2.35it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 40%|████      | 40/100 [00:19<00:27,  2.16it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 41%|████      | 41/100 [00:19<00:27,  2.12it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 42%|████▏     | 42/100 [00:20<00:29,  1.98it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 43%|████▎     | 43/100 [00:20<00:32,  1.77it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 44%|████▍     | 44/100 [00:21<00:31,  1.76it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 45%|████▌     | 45/100 [00:22<00:34,  1.59it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 46%|████▌     | 46/100 [00:23<00:37,  1.45it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 47%|████▋     | 47/100 [00:24<00:46,  1.14it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 48%|████▊     | 48/100 [00:25<00:43,  1.20it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 49%|████▉     | 49/100 [00:25<00:40,  1.27it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 50%|█████     | 50/100 [00:26<00:41,  1.21it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 51%|█████     | 51/100 [00:27<00:37,  1.29it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 52%|█████▏    | 52/100 [00:27<00:34,  1.41it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 53%|█████▎    | 53/100 [00:28<00:30,  1.52it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 54%|█████▍    | 54/100 [00:29<00:28,  1.63it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 55%|█████▌    | 55/100 [00:29<00:25,  1.74it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 56%|█████▌    | 56/100 [00:29<00:23,  1.89it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 57%|█████▋    | 57/100 [00:30<00:21,  2.02it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 58%|█████▊    | 58/100 [00:30<00:21,  1.98it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 59%|█████▉    | 59/100 [00:31<00:19,  2.09it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 60%|██████    | 60/100 [00:31<00:18,  2.18it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 61%|██████    | 61/100 [00:32<00:17,  2.22it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 62%|██████▏   | 62/100 [00:32<00:16,  2.24it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 63%|██████▎   | 63/100 [00:33<00:16,  2.27it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 64%|██████▍   | 64/100 [00:33<00:15,  2.32it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 65%|██████▌   | 65/100 [00:33<00:14,  2.34it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 66%|██████▌   | 66/100 [00:34<00:14,  2.38it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 67%|██████▋   | 67/100 [00:34<00:13,  2.41it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 68%|██████▊   | 68/100 [00:35<00:13,  2.35it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 69%|██████▉   | 69/100 [00:35<00:13,  2.35it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 70%|███████   | 70/100 [00:35<00:12,  2.35it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 71%|███████   | 71/100 [00:36<00:13,  2.13it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 72%|███████▏  | 72/100 [00:37<00:15,  1.78it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 73%|███████▎  | 73/100 [00:37<00:14,  1.87it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 74%|███████▍  | 74/100 [00:38<00:12,  2.02it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 75%|███████▌  | 75/100 [00:38<00:11,  2.14it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 76%|███████▌  | 76/100 [00:39<00:11,  2.12it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 77%|███████▋  | 77/100 [00:39<00:10,  2.19it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 78%|███████▊  | 78/100 [00:39<00:09,  2.22it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 79%|███████▉  | 79/100 [00:40<00:09,  2.12it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 80%|████████  | 80/100 [00:41<00:10,  1.99it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 81%|████████  | 81/100 [00:41<00:09,  2.08it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 82%|████████▏ | 82/100 [00:41<00:08,  2.15it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 83%|████████▎ | 83/100 [00:42<00:07,  2.23it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 84%|████████▍ | 84/100 [00:42<00:06,  2.31it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 85%|████████▌ | 85/100 [00:43<00:06,  2.30it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 86%|████████▌ | 86/100 [00:43<00:05,  2.37it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 87%|████████▋ | 87/100 [00:43<00:05,  2.36it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 88%|████████▊ | 88/100 [00:44<00:05,  2.39it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 89%|████████▉ | 89/100 [00:44<00:04,  2.42it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 90%|█████████ | 90/100 [00:45<00:04,  2.34it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 91%|█████████ | 91/100 [00:45<00:03,  2.34it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 92%|█████████▏| 92/100 [00:46<00:03,  2.34it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 93%|█████████▎| 93/100 [00:46<00:02,  2.36it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 94%|█████████▍| 94/100 [00:46<00:02,  2.33it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 95%|█████████▌| 95/100 [00:47<00:02,  2.31it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 96%|█████████▌| 96/100 [00:47<00:01,  2.33it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 97%|█████████▋| 97/100 [00:48<00:01,  2.24it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 98%|█████████▊| 98/100 [00:48<00:00,  2.24it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      " 99%|█████████▉| 99/100 [00:49<00:00,  2.25it/s]The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.02it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Need to specify at least one of 'labels', 'index' or 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrai_insights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\responsibleai\\responsibleai\\rai_insights\\rai_insights.py:426\u001b[0m, in \u001b[0;36mRAIInsights.compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"Calls compute on each of the managers.\"\"\"\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managers:\n\u001b[1;32m--> 426\u001b[0m     \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\responsibleai\\responsibleai\\managers\\error_analysis_manager.py:241\u001b[0m, in \u001b[0;36mErrorAnalysisManager.compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m min_child_samples \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmin_child_samples\n\u001b[0;32m    240\u001b[0m filter_features \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mfilter_features\n\u001b[1;32m--> 241\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_error_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_child_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_child_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_leaves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_leaves\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_importances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Validate the serialized output against schema\u001b[39;00m\n\u001b[0;32m    248\u001b[0m schema \u001b[38;5;241m=\u001b[39m ErrorAnalysisManager\u001b[38;5;241m.\u001b[39m_get_error_analysis_schema()\n",
      "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\erroranalysis\\erroranalysis\\analyzer\\error_analyzer.py:328\u001b[0m, in \u001b[0;36mBaseAnalyzer.create_error_report\u001b[1;34m(self, filter_features, max_depth, num_leaves, min_child_samples, compute_importances)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_error_report\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m                         filter_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    304\u001b[0m                         max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    305\u001b[0m                         num_leaves\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m                         min_child_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m                         compute_importances\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;124;03m\"\"\"Creates the error analysis ErrorReport.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    The ErrorReport contains the importances, heatmap and tree view json.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    :rtype: dict\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_error_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mnum_leaves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_leaves\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmin_child_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_child_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filter_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\erroranalysis\\erroranalysis\\analyzer\\error_analyzer.py:294\u001b[0m, in \u001b[0;36mBaseAnalyzer.compute_error_tree\u001b[1;34m(self, features, filters, composite_filters, max_depth, num_leaves, min_child_samples)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_error_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    266\u001b[0m                        features,\n\u001b[0;32m    267\u001b[0m                        filters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    270\u001b[0m                        num_leaves\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    271\u001b[0m                        min_child_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;124;03m\"\"\"Computes the tree view json.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    :param features: The selected features to train the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    :rtype: dict\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_error_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcomposite_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mnum_leaves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_leaves\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmin_child_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_child_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\erroranalysis\\erroranalysis\\_internal\\surrogate_error_tree.py:97\u001b[0m, in \u001b[0;36mcompute_error_tree\u001b[1;34m(analyzer, features, filters, composite_filters, max_depth, num_leaves, min_child_samples)\u001b[0m\n\u001b[0;32m     93\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_model_analyzer:\n\u001b[0;32m     96\u001b[0m     pred_y \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m---> 97\u001b[0m         \u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata_columns\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer\u001b[38;5;241m.\u001b[39mmodel_task \u001b[38;5;241m==\u001b[39m ModelTask\u001b[38;5;241m.\u001b[39mCLASSIFICATION:\n\u001b[0;32m    100\u001b[0m     diff \u001b[38;5;241m=\u001b[39m pred_y \u001b[38;5;241m!=\u001b[39m true_y\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4956\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4808\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4810\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4817\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4818\u001b[0m ):\n\u001b[0;32m   4819\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4820\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4821\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4954\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4955\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4271\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4269\u001b[0m     axes, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_axes_from_arguments((index, columns), {})\n\u001b[0;32m   4270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed to specify at least one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4273\u001b[0m     )\n\u001b[0;32m   4275\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   4277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mValueError\u001b[0m: Need to specify at least one of 'labels', 'index' or 'columns'"
     ]
    }
   ],
   "source": [
    "rai_insights.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-fleet",
   "metadata": {},
   "source": [
    "Finally, visualize and explore the model insights. Use the resulting widget or follow the link to view this in a new tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResponsibleAIDashboard(rai_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-parallel",
   "metadata": {},
   "source": [
    "## Assess Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-victoria",
   "metadata": {},
   "source": [
    "### Aggregate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-drove",
   "metadata": {},
   "source": [
    "The Error Analysis component is displayed at the top of the dashboard widget. To visualize how error is broken down across cohorts, use the tree map view to understand how it filters through the nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-painting",
   "metadata": {},
   "source": [
    "![Error Analysis tree map with \"Marital Status == 2,\" \"Capital Gain <= 1287.5,\" \"Capital Loss <= 1494.5\" path selected](./img/classification-assessment-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-heritage",
   "metadata": {},
   "source": [
    "Over 40% of the error in this model is concentrated in datapoints of people who are married, have higher education and minimal capital gain. \n",
    "\n",
    "Let's see what else we can discover about this cohort.\n",
    "\n",
    "First, save the cohort by clicking \"Save as a new cohort\" on the right side panel of the Error Analysis component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-chocolate",
   "metadata": {},
   "source": [
    "![Cohort creation sidebar and tree map cohort creation popup](./img/classification-assessment-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-reception",
   "metadata": {},
   "source": [
    "To switch to this cohort for analysis, click \"Switch global cohort\" and select the recently saved cohort from the dropdown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-shame",
   "metadata": {},
   "source": [
    "![Popup with dropdown to shift cohort from \"All data\" to \"Married, Low Capital Loss/Gain\" accompanied by cohort statistics](./img/classification-assessment-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-alpha",
   "metadata": {},
   "source": [
    "The Model Overview component allows the comparison of statistics across multiple saved cohorts.\n",
    "\n",
    "The diagram indicates that the model is misclassifying datapoints of married individuals with low capital gains and high education as lower income (false negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-wheel",
   "metadata": {},
   "source": [
    "![Bar chart of classification outcomes (true negative, true positive, false negative, false positive) compared across cohorts](./img/classification-assessment-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-commission",
   "metadata": {},
   "source": [
    "Looking at the ground truth statistics of the overall data and the erroneous cohort, we realize there are opposite patterns in terms of high income representation in ground truth. While the overall data is representing more individuals with actual income of <= 50K, the married individuals with low capital gains and high education represent more individuals with actual income of > 50K. Given the small size of the dataset and this reverse pattern, the model makes more mistakes in predicting high income individuals. One action item is to collect a lot more data in both cohorts and retrain the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-specific",
   "metadata": {},
   "source": [
    "![image-3.png](./img/classification-assessment-5.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "published-dancing",
   "metadata": {},
   "source": [
    "![image.png](./img/classification-assessment-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-huntington",
   "metadata": {},
   "source": [
    "The Interpretability component displays feature importances for model predictions at an individual and aggregate level. The plot below indicates that the `marital-status` attribute influence model predictions the most on average."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "danish-stadium",
   "metadata": {},
   "source": [
    "![Top 5 features of the cohort, in descending importance: relationship, age, capital gain, education-num, hours per week](./img/classification-assessment-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-management",
   "metadata": {},
   "source": [
    "The lower half of this tab specifies how marita status affects model prediction. Being a husband or wife (married-civ-spouse) is more likely to pull the prediction away from <=50k, possibly because couples have a higher cumulative income."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "nervous-confusion",
   "metadata": {},
   "source": [
    "![Feature importance stratified by relationship](./img/classification-assessment-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-bench",
   "metadata": {},
   "source": [
    "### Individual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-market",
   "metadata": {},
   "source": [
    "Let's revisit Data Explorer. In the \"Individual datapoints\" view, we can see the prediction probabilities of each point. Point 510 is one that was just above the threshold to be classified as income of > 50K."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "under-seminar",
   "metadata": {},
   "source": [
    "![Scatter plot of prediction probabilities (rounded to 0.2) on the y-axis and index on the x-axis](./img/classification-assessment-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-maximum",
   "metadata": {},
   "source": [
    "What factors led the model to make this decision?\n",
    "\n",
    "The \"Individual feature importance\" tab in the Interpretability component's Feature Importances section let you select points for further analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "medium-broadcasting",
   "metadata": {},
   "source": [
    "![Table of datapoints with row 510 selected](./img/classification-assessment-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-frank",
   "metadata": {},
   "source": [
    "Under this, the feature importance plot shows `capital-gain` and `native-country` as the most significant factors leading to the <= 50K classification. Changing these may cause the threshold to be crossed and the model to predict the opposite class. Please note that depending on the context, the high importance of `native-country` might be considered as a fairness issue."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "super-cambodia",
   "metadata": {},
   "source": [
    "![Feature importance plot for classification of 0 (descending, positive to negative): age, hours per week, capital gain, race, education-num, workclass, sex, country, occupation, marital status, relationship, capital loss](./img/classification-assessment-11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-quantum",
   "metadata": {},
   "source": [
    "The What-If Counterfactuals component focuses on how to change features slightly in order to change model predictions. As seen in its top ranked features bar plot, changing this person's marital-status, capital-loss, and education-num have the highest impact on flipping the prediction to > 50K."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "rough-uncle",
   "metadata": {},
   "source": [
    "![Top-ranked features (descending) for datapoint 510 to perturb to flip model prediction: age, hours per week, capital gain, capital loss, marital status, occupation, education-num, workclass, relationship, race, sex, country](./img/classification-assessment-12.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
