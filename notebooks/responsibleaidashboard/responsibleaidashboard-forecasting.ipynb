{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Responsible AI dashboard for Time Series Forecasting\n",
        "_**Orange Juice Sales Forecasting**_\n",
        "\n",
        "## Contents\n",
        "1. [Introduction](#introduction)\n",
        "1. [Setup](#setup)\n",
        "1. [Compute](#compute)\n",
        "1. [Data](#data)\n",
        "1. [Train](#train)\n",
        "1. [Forecast](#forecast)\n",
        "1. [Operationalize](#operationalize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction<a id=\"introduction\"></a>\n",
        "In this example, we use AutoML to train, select, and operationalize a time-series forecasting model for multiple time-series.\n",
        "\n",
        "Make sure you have executed the [configuration notebook](../../../configuration.ipynb) before running this notebook.\n",
        "\n",
        "The examples in the follow code samples use the University of Chicago's Dominick's Finer Foods dataset to forecast orange juice sales. Dominick's was a grocery chain in the Chicago metropolitan area."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup<a id=\"setup\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1670990788014
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.automl.core.featurization import FeaturizationConfig\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set this to False if you're running this for the first time.\n",
        "# For all subsequent executions you can reuse your existing model by loading it from AzureML.\n",
        "# Simply set the flag to True.\n",
        "precomputed = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is compatible with Azure ML SDK version 1.35.0 or later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1670990791453
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are currently using version 1.48.0 of the Azure ML SDK\n"
          ]
        }
      ],
      "source": [
        "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As part of the setup you have already created a <b>Workspace</b>. To run AutoML, you also need to create an <b>Experiment</b>. An Experiment corresponds to a prediction problem you are trying to solve, while a Run corresponds to a specific approach to the problem. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1670990845342
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Subscription ID</th>\n",
              "      <td>b3b0e63c-e8fd-4f5c-bab9-1ed82844ef1f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Workspace</th>\n",
              "      <td>romanlutz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SKU</th>\n",
              "      <td>Basic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Resource Group</th>\n",
              "      <td>romanlutz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Location</th>\n",
              "      <td>canadacentral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Run History Name</th>\n",
              "      <td>automl-ojforecasting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SDK Version</th>\n",
              "      <td>1.48.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      \n",
              "Subscription ID   b3b0e63c-e8fd-4f5c-bab9-1ed82844ef1f\n",
              "Workspace                                    romanlutz\n",
              "SKU                                              Basic\n",
              "Resource Group                               romanlutz\n",
              "Location                                 canadacentral\n",
              "Run History Name                  automl-ojforecasting\n",
              "SDK Version                                     1.48.0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for the run history container in the workspace\n",
        "experiment_name = \"automl-ojforecasting\"\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "\n",
        "output = {}\n",
        "output[\"Subscription ID\"] = ws.subscription_id\n",
        "output[\"Workspace\"] = ws.name\n",
        "output[\"SKU\"] = ws.sku\n",
        "output[\"Resource Group\"] = ws.resource_group\n",
        "output[\"Location\"] = ws.location\n",
        "output[\"Run History Name\"] = experiment_name\n",
        "output[\"SDK Version\"] = azureml.core.VERSION\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
        "outputDf.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute<a id=\"compute\"></a>\n",
        "You will need to create a [compute target](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute) for your AutoML run. In this tutorial, you create AmlCompute as your training compute resource.\n",
        "\n",
        "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist.\n",
        "\n",
        "#### Creation of AmlCompute takes approximately 5 minutes. \n",
        "If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
        "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1670990859041
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "amlcompute_cluster_name = \"oj-cluster\"\n",
        "\n",
        "if not precomputed:\n",
        "    # Verify that cluster does not exist already\n",
        "    try:\n",
        "        compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "        print(\"Found existing cluster, use it.\")\n",
        "    except ComputeTargetException:\n",
        "        compute_config = AmlCompute.provisioning_configuration(\n",
        "            vm_size=\"STANDARD_D12_V2\", max_nodes=6\n",
        "        )\n",
        "        compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data<a id=\"data\"></a>\n",
        "You are now ready to load the historical orange juice sales data. We will load the CSV file into a plain pandas DataFrame; the time column in the CSV is called _WeekStarting_, so it will be specially parsed into the datetime type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1670990899201
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WeekStarting</th>\n",
              "      <th>Store</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Advert</th>\n",
              "      <th>Price</th>\n",
              "      <th>Age60</th>\n",
              "      <th>COLLEGE</th>\n",
              "      <th>INCOME</th>\n",
              "      <th>Hincome150</th>\n",
              "      <th>Large HH</th>\n",
              "      <th>Minorities</th>\n",
              "      <th>WorkingWoman</th>\n",
              "      <th>SSTRDIST</th>\n",
              "      <th>SSTRVOL</th>\n",
              "      <th>CPDIST5</th>\n",
              "      <th>CPWVOL5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1990-06-14</td>\n",
              "      <td>2</td>\n",
              "      <td>dominicks</td>\n",
              "      <td>10560</td>\n",
              "      <td>1</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.114280</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.927280</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1990-06-14</td>\n",
              "      <td>2</td>\n",
              "      <td>minute.maid</td>\n",
              "      <td>4480</td>\n",
              "      <td>0</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.114280</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.927280</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1990-06-14</td>\n",
              "      <td>2</td>\n",
              "      <td>tropicana</td>\n",
              "      <td>8256</td>\n",
              "      <td>0</td>\n",
              "      <td>3.87</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.114280</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.927280</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1990-06-14</td>\n",
              "      <td>5</td>\n",
              "      <td>dominicks</td>\n",
              "      <td>1792</td>\n",
              "      <td>1</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.117368</td>\n",
              "      <td>0.321226</td>\n",
              "      <td>10.922371</td>\n",
              "      <td>0.535883</td>\n",
              "      <td>0.103092</td>\n",
              "      <td>0.053875</td>\n",
              "      <td>0.410568</td>\n",
              "      <td>3.801998</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>1.600573</td>\n",
              "      <td>0.736307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1990-06-14</td>\n",
              "      <td>5</td>\n",
              "      <td>minute.maid</td>\n",
              "      <td>4224</td>\n",
              "      <td>0</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.117368</td>\n",
              "      <td>0.321226</td>\n",
              "      <td>10.922371</td>\n",
              "      <td>0.535883</td>\n",
              "      <td>0.103092</td>\n",
              "      <td>0.053875</td>\n",
              "      <td>0.410568</td>\n",
              "      <td>3.801998</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>1.600573</td>\n",
              "      <td>0.736307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WeekStarting  Store        Brand  Quantity  Advert  Price     Age60  \\\n",
              "0   1990-06-14      2    dominicks     10560       1   1.59  0.232865   \n",
              "1   1990-06-14      2  minute.maid      4480       0   3.17  0.232865   \n",
              "2   1990-06-14      2    tropicana      8256       0   3.87  0.232865   \n",
              "3   1990-06-14      5    dominicks      1792       1   1.59  0.117368   \n",
              "4   1990-06-14      5  minute.maid      4224       0   2.99  0.117368   \n",
              "\n",
              "    COLLEGE     INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n",
              "0  0.248935  10.553205    0.463887  0.103953    0.114280      0.303585   \n",
              "1  0.248935  10.553205    0.463887  0.103953    0.114280      0.303585   \n",
              "2  0.248935  10.553205    0.463887  0.103953    0.114280      0.303585   \n",
              "3  0.321226  10.922371    0.535883  0.103092    0.053875      0.410568   \n",
              "4  0.321226  10.922371    0.535883  0.103092    0.053875      0.410568   \n",
              "\n",
              "   SSTRDIST   SSTRVOL   CPDIST5   CPWVOL5  \n",
              "0  2.110122  1.142857  1.927280  0.376927  \n",
              "1  2.110122  1.142857  1.927280  0.376927  \n",
              "2  2.110122  1.142857  1.927280  0.376927  \n",
              "3  3.801998  0.681818  1.600573  0.736307  \n",
              "4  3.801998  0.681818  1.600573  0.736307  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "time_column_name = \"WeekStarting\"\n",
        "dataset_location = \"https://raw.githubusercontent.com/Azure/azureml-examples/2fe81643865e1f4591e7734bd1a729093cafb826/v1/python-sdk/tutorials/automl-with-azureml/forecasting-orange-juice-sales/dominicks_OJ.csv\"\n",
        "data = pd.read_csv(dataset_location, parse_dates=[time_column_name])\n",
        "\n",
        "# Drop the columns 'logQuantity' as it is a leaky feature.\n",
        "data.drop(\"logQuantity\", axis=1, inplace=True)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each row in the DataFrame holds a quantity of weekly sales for an OJ brand at a single store. The data also includes the sales price, a flag indicating if the OJ brand was advertised in the store that week, and some customer demographic information based on the store location. For historical reasons, the data also include the logarithm of the sales quantity. The Dominick's grocery data is commonly used to illustrate econometric modeling techniques where logarithms of quantities are generally preferred.    \n",
        "\n",
        "The task is now to build a time-series model for the _Quantity_ column. It is important to note that this dataset is comprised of many individual time-series - one for each unique combination of _Store_ and _Brand_. To distinguish the individual time-series, we define the **time_series_id_column_names** - the columns whose values determine the boundaries between time-series: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1670990902872
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data contains 249 individual time-series.\n"
          ]
        }
      ],
      "source": [
        "time_series_id_column_names = [\"Store\", \"Brand\"]\n",
        "nseries = data.groupby(time_series_id_column_names).ngroups\n",
        "print(\"Data contains {0} individual time-series.\".format(nseries))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For demonstration purposes, we extract sales time-series for just a few of the stores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1670990905562
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data subset contains 9 individual time-series.\n"
          ]
        }
      ],
      "source": [
        "use_stores = [2, 5, 8]\n",
        "data_subset = data[data.Store.isin(use_stores)]\n",
        "nseries = data_subset.groupby(time_series_id_column_names).ngroups\n",
        "print(\"Data subset contains {0} individual time-series.\".format(nseries))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Splitting\n",
        "We now split the data into a training and a testing set for later forecast evaluation. The test set will contain the final 20 weeks of observed sales for each time-series. The splits should be stratified by series, so we use a group-by statement on the time series identifier columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1670990907583
        }
      },
      "outputs": [],
      "source": [
        "n_test_periods = 20\n",
        "\n",
        "\n",
        "def split_last_n_by_series_id(df, n):\n",
        "    \"\"\"Group df by series identifiers and split on last n rows for each group.\"\"\"\n",
        "    df_grouped = df.sort_values(time_column_name).groupby(  # Sort by ascending time\n",
        "        time_series_id_column_names, group_keys=False\n",
        "    )\n",
        "    df_head = df_grouped.apply(lambda dfg: dfg.iloc[:-n])\n",
        "    df_tail = df_grouped.apply(lambda dfg: dfg.iloc[-n:])\n",
        "    return df_head, df_tail\n",
        "\n",
        "\n",
        "train, test = split_last_n_by_series_id(data_subset, n_test_periods)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload data to datastore\n",
        "The [Machine Learning service workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-workspace), is paired with the storage account, which contains the default data store. We will use it to upload the train and test data and create [tabular datasets](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py) for training and testing. A tabular dataset defines a series of lazily-evaluated, immutable operations to load data from the data source into tabular representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1670990919589
        }
      },
      "outputs": [],
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "if not precomputed:\n",
        "    datastore = ws.get_default_datastore()\n",
        "    train_dataset = TabularDatasetFactory.register_pandas_dataframe(\n",
        "        train, target=(datastore, \"dataset/\"), name=\"dominicks_OJ_train\"\n",
        "    )\n",
        "    test_dataset = TabularDatasetFactory.register_pandas_dataframe(\n",
        "        test, target=(datastore, \"dataset/\"), name=\"dominicks_OJ_test\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create dataset for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1670990920397
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      WeekStarting  Store      Brand  Quantity  Advert  Price     Age60  \\\n",
            "22721   1992-04-09      8  tropicana     16192       0   2.50  0.252394   \n",
            "22967   1992-04-16      8  tropicana      6528       0   2.89  0.252394   \n",
            "23213   1992-04-23      8  tropicana      8320       0   2.89  0.252394   \n",
            "23462   1992-04-30      8  tropicana     30784       1   2.16  0.252394   \n",
            "23711   1992-05-07      8  tropicana     18048       0   2.89  0.252394   \n",
            "\n",
            "        COLLEGE    INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n",
            "22721  0.095173  10.59701    0.054227   0.13175    0.035243      0.283075   \n",
            "22967  0.095173  10.59701    0.054227   0.13175    0.035243      0.283075   \n",
            "23213  0.095173  10.59701    0.054227   0.13175    0.035243      0.283075   \n",
            "23462  0.095173  10.59701    0.054227   0.13175    0.035243      0.283075   \n",
            "23711  0.095173  10.59701    0.054227   0.13175    0.035243      0.283075   \n",
            "\n",
            "       SSTRDIST  SSTRVOL   CPDIST5   CPWVOL5  \n",
            "22721  2.636333      1.5  2.905384  0.641016  \n",
            "22967  2.636333      1.5  2.905384  0.641016  \n",
            "23213  2.636333      1.5  2.905384  0.641016  \n",
            "23462  2.636333      1.5  2.905384  0.641016  \n",
            "23711  2.636333      1.5  2.905384  0.641016  \n"
          ]
        }
      ],
      "source": [
        "if precomputed:\n",
        "    print(train.tail())\n",
        "else:\n",
        "    print(train_dataset.to_pandas_dataframe().tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling\n",
        "\n",
        "For forecasting tasks, AutoML uses pre-processing and estimation steps that are specific to time-series. AutoML will undertake the following pre-processing steps:\n",
        "* Detect time-series sample frequency (e.g. hourly, daily, weekly) and create new records for absent time points to make the series regular. A regular time series has a well-defined frequency and has a value at every sample point in a contiguous time span \n",
        "* Impute missing values in the target (via forward-fill) and feature columns (using median column values) \n",
        "* Create features based on time series identifiers to enable fixed effects across different series\n",
        "* Create time-based features to assist in learning seasonal patterns\n",
        "* Encode categorical variables to numeric quantities\n",
        "\n",
        "In this notebook, AutoML will train a single, regression-type model across **all** time-series in a given training set. This allows the model to generalize across related series. If you're looking for training multiple models for different time-series, please see the many-models notebook.\n",
        "\n",
        "You are almost ready to start an AutoML training job. First, we need to separate the target column from the rest of the DataFrame: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1670990924966
        }
      },
      "outputs": [],
      "source": [
        "target_column_name = \"Quantity\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customization\n",
        "\n",
        "The featurization customization in forecasting is an advanced feature in AutoML which allows our customers to change the default forecasting featurization behaviors and column types through `FeaturizationConfig`. The supported scenarios include:\n",
        "\n",
        "1. Column purposes update: Override feature type for the specified column. Currently supports DateTime, Categorical and Numeric. This customization can be used in the scenario that the type of the column cannot correctly reflect its purpose. Some numerical columns, for instance, can be treated as Categorical columns which need to be converted to categorical while some can be treated as epoch timestamp which need to be converted to datetime. To tell our SDK to correctly preprocess these columns, a configuration need to be add with the columns and their desired types.\n",
        "2. Transformer parameters update: Currently supports parameter change for Imputer only. User can customize imputation methods. The supported imputing methods for target column are constant and ffill (forward fill). The supported imputing methods for feature columns are mean, median, most frequent, constant and ffill (forward fill). This customization can be used for the scenario that our customers know which imputation methods fit best to the input data. For instance, some datasets use NaN to represent 0 which the correct behavior should impute all the missing value with 0. To achieve this behavior, these columns need to be configured as constant imputation with `fill_value` 0.\n",
        "3. Drop columns: Columns to drop from being featurized. These usually are the columns which are leaky or the columns contain no useful data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1670990927322
        },
        "tags": [
          "sample-featurizationconfig-remarks"
        ]
      },
      "outputs": [],
      "source": [
        "featurization_config = FeaturizationConfig()\n",
        "# Force the CPWVOL5 feature to be numeric type.\n",
        "featurization_config.add_column_purpose(\"CPWVOL5\", \"Numeric\")\n",
        "# Fill missing values in the target column, Quantity, with zeros.\n",
        "featurization_config.add_transformer_params(\n",
        "    \"Imputer\", [\"Quantity\"], {\"strategy\": \"constant\", \"fill_value\": 0}\n",
        ")\n",
        "# Fill missing values in the INCOME column with median value.\n",
        "featurization_config.add_transformer_params(\n",
        "    \"Imputer\", [\"INCOME\"], {\"strategy\": \"median\"}\n",
        ")\n",
        "# Fill missing values in the Price column with forward fill (last value carried forward).\n",
        "featurization_config.add_transformer_params(\"Imputer\", [\"Price\"], {\"strategy\": \"ffill\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forecasting Parameters\n",
        "To define forecasting parameters for your experiment training, you can leverage the ForecastingParameters class. The table below details the forecasting parameter we will be passing into our experiment.\n",
        "\n",
        "\n",
        "|Property|Description|\n",
        "|-|-|\n",
        "|**time_column_name**|The name of your time column.|\n",
        "|**forecast_horizon**|The forecast horizon is how many periods forward you would like to forecast. This integer horizon is in units of the timeseries frequency (e.g. daily, weekly).|\n",
        "|**time_series_id_column_names**|The column names used to uniquely identify the time series in data that has multiple rows with the same timestamp. If the time series identifiers are not defined, the data set is assumed to be one time series.|\n",
        "|**freq**|Forecast frequency. This optional parameter represents the period with which the forecast is desired, for example, daily, weekly, yearly, etc. Use this parameter for the correction of time series containing irregular data points or for padding of short time series. The frequency needs to be a pandas offset alias. Please refer to [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects) for more information.\n",
        "|**cv_step_size**|Number of periods between two consecutive cross-validation folds. The default value is \"auto\", in which case AutoMl determines the cross-validation step size automatically, if a validation set is not provided. Or users could specify an integer value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train<a id=\"train\"></a>\n",
        "\n",
        "The [AutoMLConfig](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py) object defines the settings and data for an AutoML training job. Here, we set necessary inputs like the task type, the number of AutoML iterations to try, the training data, and cross-validation parameters.\n",
        "\n",
        "For forecasting tasks, there are some additional parameters that can be set in the `ForecastingParameters` class: the name of the column holding the date/time, the timeseries id column names, and the maximum forecast horizon. A time column is required for forecasting, while the time_series_id is optional. If time_series_id columns are not given, AutoML assumes that the whole dataset is a single time-series. We also pass a list of columns to drop prior to modeling. The _logQuantity_ column is completely correlated with the target quantity, so it must be removed to prevent a target leak.\n",
        "\n",
        "The forecast horizon is given in units of the time-series frequency; for instance, the OJ series frequency is weekly, so a horizon of 20 means that a trained model will estimate sales up to 20 weeks beyond the latest date in the training data for each series. In this example, we set the forecast horizon to the number of samples per series in the test set (n_test_periods). Generally, the value of this parameter will be dictated by business needs. For example, a demand planning application that estimates the next month of sales should set the horizon according to suitable planning time-scales. Please see the [energy_demand notebook](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning/forecasting-energy-demand) for more discussion of forecast horizon.\n",
        "\n",
        "We note here that AutoML can sweep over two types of time-series models:\n",
        "* Models that are trained for each series such as ARIMA and Facebook's Prophet.\n",
        "* Models trained across multiple time-series using a regression approach.\n",
        "\n",
        "In the first case, AutoML loops over all time-series in your dataset and trains one model (e.g. AutoArima or Prophet, as the case may be) for each series. This can result in long runtimes to train these models if there are a lot of series in the data. One way to mitigate this problem is to fit models for different series in parallel if you have multiple compute cores available. To enable this behavior, set the `max_cores_per_iteration` parameter in your AutoMLConfig as shown in the example in the next cell. \n",
        "\n",
        "\n",
        "Finally, a note about the cross-validation (CV) procedure for time-series data. AutoML uses out-of-sample error estimates to select a best pipeline/model, so it is important that the CV fold splitting is done correctly. Time-series can violate the basic statistical assumptions of the canonical K-Fold CV strategy, so AutoML implements a [rolling origin validation](https://robjhyndman.com/hyndsight/tscv/) procedure to create CV folds for time-series data. To use this procedure, you could specify the desired number of CV folds and the number of periods between two consecutive folds in the AutoMLConfig object, or AutoMl could set them automatically if you don't specify them. It is also possible to bypass CV and use your own validation set by setting the *validation_data* parameter of AutoMLConfig.\n",
        "\n",
        "Here is a summary of AutoMLConfig parameters used for training the OJ model:\n",
        "\n",
        "|Property|Description|\n",
        "|-|-|\n",
        "|**task**|forecasting|\n",
        "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>\n",
        "|**experiment_timeout_hours**|Experimentation timeout in hours.|\n",
        "|**enable_early_stopping**|If early stopping is on, training will stop when the primary metric is no longer improving.|\n",
        "|**training_data**|Input dataset, containing both features and label column.|\n",
        "|**label_column_name**|The name of the label column.|\n",
        "|**compute_target**|The remote compute for training.|\n",
        "|**n_cross_validations**|Number of cross-validation folds to use for model/pipeline selection. The default value is \"auto\", in which case AutoMl determines the number of cross-validations automatically, if a validation set is not provided. Or users could specify an integer value.\n",
        "|**enable_voting_ensemble**|Allow AutoML to create a Voting ensemble of the best performing models|\n",
        "|**enable_stack_ensemble**|Allow AutoML to create a Stack ensemble of the best performing models|\n",
        "|**debug_log**|Log file path for writing debugging information|\n",
        "|**featurization**| 'auto' / 'off' / FeaturizationConfig Indicator for whether featurization step should be done automatically or not, or whether customized featurization should be used. Setting this enables AutoML to perform featurization on the input to handle *missing data*, and to perform some common *feature extraction*.|\n",
        "|**max_cores_per_iteration**|Maximum number of cores to utilize per iteration. A value of -1 indicates all available cores should be used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1670990930838
        }
      },
      "outputs": [],
      "source": [
        "from azureml.automl.core.forecasting_parameters import ForecastingParameters\n",
        "\n",
        "if not precomputed:\n",
        "    forecasting_parameters = ForecastingParameters(\n",
        "        time_column_name=time_column_name,\n",
        "        forecast_horizon=n_test_periods,\n",
        "        time_series_id_column_names=time_series_id_column_names,\n",
        "        freq=\"W-THU\",  # Set the forecast frequency to be weekly (start on each Thursday)\n",
        "        cv_step_size=\"auto\"\n",
        "    )\n",
        "\n",
        "    blocked_models = ['Naive', 'SeasonalNaive', 'Average', 'SeasonalAverage',\n",
        "                      'AutoArima', 'Arimax', 'Prophet', 'ExponentialSmoothing',\n",
        "                      'XGBoost']\n",
        "\n",
        "    automl_config = AutoMLConfig(\n",
        "        task=\"forecasting\",\n",
        "        debug_log=\"automl_oj_sales_errors.log\",\n",
        "        primary_metric=\"normalized_mean_absolute_error\",\n",
        "        experiment_timeout_hours=0.25,\n",
        "        training_data=train_dataset,\n",
        "        label_column_name=target_column_name,\n",
        "        compute_target=compute_target,\n",
        "        enable_early_stopping=True,\n",
        "        featurization=featurization_config,\n",
        "        n_cross_validations=\"auto\",  # Feel free to set to a small integer (>=2) if runtime is an issue.\n",
        "        verbosity=logging.INFO,\n",
        "        max_cores_per_iteration=-1,\n",
        "        forecasting_parameters=forecasting_parameters,\n",
        "        iterations=15,\n",
        "        blocked_models=blocked_models\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now submit a new training run. Depending on the data and number of iterations this operation may take several minutes.\n",
        "Information from each iteration will be printed to the console.  Validation errors and current status will be shown when setting `show_output=True` and the execution will be synchronous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1670990939835
        }
      },
      "outputs": [],
      "source": [
        "if not precomputed:\n",
        "    remote_run = experiment.submit(automl_config, show_output=False)\n",
        "    remote_run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Retrieve the Best Run details\n",
        "Below we retrieve the best Run object from among all the runs in the experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1670992191501
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-ojforecasting</td><td>AutoML_198e432f-4caa-48bb-97f7-7a01e8acae01_35</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_198e432f-4caa-48bb-97f7-7a01e8acae01_35?wsid=/subscriptions/b3b0e63c-e8fd-4f5c-bab9-1ed82844ef1f/resourcegroups/romanlutz/workspaces/romanlutz&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: automl-ojforecasting,\n",
              "Id: AutoML_198e432f-4caa-48bb-97f7-7a01e8acae01_35,\n",
              "Type: azureml.scriptrun,\n",
              "Status: Completed)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if precomputed:\n",
        "    remote_run = list(experiment.get_runs())[0]\n",
        "best_run = remote_run.get_best_child()\n",
        "model_name = best_run.properties[\"model_name\"]\n",
        "best_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transparency\n",
        "\n",
        "View updated featurization summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1670992191841
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RawFeatureName</th>\n",
              "      <th>TypeDetected</th>\n",
              "      <th>Dropped</th>\n",
              "      <th>EngineeredFeatureCount</th>\n",
              "      <th>Transformations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Advert</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Price</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[FowardFillImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Age60</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COLLEGE</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>INCOME</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Hincome150</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Large HH</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Minorities</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>WorkingWoman</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SSTRDIST</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SSTRVOL</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CPDIST5</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CPWVOL5</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>[MedianImputer, ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>_automl_target_col</td>\n",
              "      <td>Numeric</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>[ImputationMarker]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Store</td>\n",
              "      <td>Ignore</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>[GrainMarker-LabelEncoder]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Brand</td>\n",
              "      <td>Ignore</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>[GrainMarker-LabelEncoder]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>WeekStarting</td>\n",
              "      <td>DateTime</td>\n",
              "      <td>No</td>\n",
              "      <td>6</td>\n",
              "      <td>[DateTimeTransformer]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        RawFeatureName TypeDetected Dropped  EngineeredFeatureCount  \\\n",
              "0               Advert      Numeric      No                       2   \n",
              "1                Price      Numeric      No                       2   \n",
              "2                Age60      Numeric      No                       2   \n",
              "3              COLLEGE      Numeric      No                       2   \n",
              "4               INCOME      Numeric      No                       2   \n",
              "5           Hincome150      Numeric      No                       2   \n",
              "6             Large HH      Numeric      No                       2   \n",
              "7           Minorities      Numeric      No                       2   \n",
              "8         WorkingWoman      Numeric      No                       2   \n",
              "9             SSTRDIST      Numeric      No                       2   \n",
              "10             SSTRVOL      Numeric      No                       2   \n",
              "11             CPDIST5      Numeric      No                       2   \n",
              "12             CPWVOL5      Numeric      No                       2   \n",
              "13  _automl_target_col      Numeric      No                       1   \n",
              "14               Store       Ignore     Yes                       1   \n",
              "15               Brand       Ignore     Yes                       1   \n",
              "16        WeekStarting     DateTime      No                       6   \n",
              "\n",
              "                          Transformations  \n",
              "0       [MedianImputer, ImputationMarker]  \n",
              "1   [FowardFillImputer, ImputationMarker]  \n",
              "2       [MedianImputer, ImputationMarker]  \n",
              "3       [MedianImputer, ImputationMarker]  \n",
              "4       [MedianImputer, ImputationMarker]  \n",
              "5       [MedianImputer, ImputationMarker]  \n",
              "6       [MedianImputer, ImputationMarker]  \n",
              "7       [MedianImputer, ImputationMarker]  \n",
              "8       [MedianImputer, ImputationMarker]  \n",
              "9       [MedianImputer, ImputationMarker]  \n",
              "10      [MedianImputer, ImputationMarker]  \n",
              "11      [MedianImputer, ImputationMarker]  \n",
              "12      [MedianImputer, ImputationMarker]  \n",
              "13                     [ImputationMarker]  \n",
              "14             [GrainMarker-LabelEncoder]  \n",
              "15             [GrainMarker-LabelEncoder]  \n",
              "16                  [DateTimeTransformer]  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the featurization summary JSON file locally\n",
        "best_run.download_file(\n",
        "    \"outputs/featurization_summary.json\", \"featurization_summary.json\"\n",
        ")\n",
        "\n",
        "# Render the JSON as a pandas DataFrame\n",
        "with open(\"featurization_summary.json\", \"r\") as f:\n",
        "    records = json.load(f)\n",
        "fs = pd.DataFrame.from_records(records)\n",
        "\n",
        "# View a summary of the featurization\n",
        "fs[\n",
        "    [\n",
        "        \"RawFeatureName\",\n",
        "        \"TypeDetected\",\n",
        "        \"Dropped\",\n",
        "        \"EngineeredFeatureCount\",\n",
        "        \"Transformations\",\n",
        "    ]\n",
        "]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forecast<a id=\"forecast\"></a>\n",
        "\n",
        "Now that we have retrieved the best pipeline/model, it can be used to make predictions on test data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Retrieving forecasts from the model\n",
        "\n",
        "To produce predictions on the test set, we need to know the feature values at all dates in the test set. This requirement is somewhat reasonable for the OJ sales data since the features mainly consist of price, which is usually set in advance, and customer demographics which are approximately constant for each store over the 20 week forecast horizon in the testing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Try downloading the model and running forecasts locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1671040294463
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ForecastingPipelineWrapper(pipeline=Pipeline(memory=None,\n",
              "                                             steps=[('timeseriestransformer',\n",
              "                                                     TimeSeriesTransformer(country_or_region=None, drop_column_names=[], featurization_config=FeaturizationConfig(blocked_transformers=None, column_purposes={'CPWVOL5': 'Numeric'}, dataset_language=None, prediction_transform_type=None, transformer_params={'Imputer': [[['_au...\n",
              "                                                     PreFittedSoftVotingRegressor(estimators=[('29', Pipeline(memory=None, steps=[('robustscaler', RobustScaler(copy=True, quantile_range=[25, 75], with_centering=True, with_scaling=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse', max_depth=None, max_features=0.7, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01091729022778783, min_samples_split=0.0012814223889440828, min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('24', Pipeline(memory=None, steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('randomforestregressor', RandomForestRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse', max_depth=None, max_features=0.7, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.004196633747563344, min_samples_split=0.008991789964660124, min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('12', Pipeline(memory=None, steps=[('robustscaler', RobustScaler(copy=True, quantile_range=[10, 90], with_centering=False, with_scaling=True)), ('decisiontreeregressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.007594568292413517, min_samples_split=0.000630957344480193, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=None, splitter='best'))], verbose=False)), ('3', Pipeline(memory=None, steps=[('seasonalaverage', SeasonalAverage(timeseries_param_dict={'time_column_name': 'WeekStarting', 'grain_column_names': ['Store', 'Brand'], 'target_column_name': 'Quantity', 'drop_column_names': [], 'overwrite_columns': True, 'dropna': False, 'transform_dictionary': {'min': '_automl_target_col', 'max': '_automl_target_col', 'mean': '_automl_target_col'}, 'max_horizon': 20, 'origin_time_colname': 'origin', 'country_or_region': None, 'n_cross_validations': 5, 'short_series_handling': True, 'max_cores_per_iteration': -1, 'feature_lags': None, 'target_aggregation_function': None, 'cv_step_size': 1, 'seasonality': 4, 'use_stl': None, 'freq': 'W-THU', 'short_series_handling_configuration': 'auto', 'target_lags': [0], 'target_rolling_window_size': 0, 'arimax_raw_columns': ['INCOME', 'WeekStarting', 'WorkingWoman', 'Brand', 'Advert', 'SSTRVOL', 'CPDIST5', 'Minorities', 'COLLEGE', 'SSTRDIST', 'Age60', 'CPWVOL5', 'Hincome150', 'Large HH', 'Price', 'Store']}))], verbose=False)), ('14', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('decisiontreeregressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=None, max_features=0.9, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.011942468634416342, min_samples_split=0.005285388593079247, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=None, splitter='best'))], verbose=False)), ('26', Pipeline(memory=None, steps=[('robustscaler', RobustScaler(copy=True, quantile_range=[10, 90], with_centering=False, with_scaling=False)), ('decisiontreeregressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.011942468634416342, min_samples_split=0.052853885930792446, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=None, splitter='best'))], verbose=False)), ('20', Pipeline(memory=None, steps=[('robustscaler', RobustScaler(copy=True, quantile_range=[10, 90], with_centering=True, with_scaling=False)), ('decisiontreeregressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None, max_features=0.9, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.007594568292413517, min_samples_split=0.0037087774117744725, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=None, splitter='best'))], verbose=False)), ('7', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('lightgbmregressor', LightGBMRegressor(min_data_in_leaf=20, n_jobs=-1, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None))], verbose=False))], weights=[0.26666666666666666, 0.26666666666666666, 0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]))],\n",
              "                                             verbose=False),\n",
              "                           stddev=[19191.233451042073])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "best_run.download_file('outputs/model.pkl')\n",
        "model = joblib.load('model.pkl')\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1671040765169
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WeekStarting</th>\n",
              "      <th>Store</th>\n",
              "      <th>Brand</th>\n",
              "      <th>0.025</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.975</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1992-05-21</td>\n",
              "      <td>2</td>\n",
              "      <td>dominicks</td>\n",
              "      <td>-28968.22</td>\n",
              "      <td>8645.90</td>\n",
              "      <td>46260.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1992-05-28</td>\n",
              "      <td>2</td>\n",
              "      <td>dominicks</td>\n",
              "      <td>-43880.52</td>\n",
              "      <td>9313.88</td>\n",
              "      <td>62508.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1992-06-04</td>\n",
              "      <td>2</td>\n",
              "      <td>dominicks</td>\n",
              "      <td>-55071.76</td>\n",
              "      <td>10077.82</td>\n",
              "      <td>75227.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1992-06-11</td>\n",
              "      <td>2</td>\n",
              "      <td>dominicks</td>\n",
              "      <td>-71355.45</td>\n",
              "      <td>3872.80</td>\n",
              "      <td>79101.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1992-06-18</td>\n",
              "      <td>2</td>\n",
              "      <td>dominicks</td>\n",
              "      <td>-79654.61</td>\n",
              "      <td>4453.13</td>\n",
              "      <td>88560.87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WeekStarting  Store      Brand     0.025      0.5    0.975\n",
              "0   1992-05-21      2  dominicks -28968.22  8645.90 46260.03\n",
              "1   1992-05-28      2  dominicks -43880.52  9313.88 62508.29\n",
              "2   1992-06-04      2  dominicks -55071.76 10077.82 75227.40\n",
              "3   1992-06-11      2  dominicks -71355.45  3872.80 79101.05\n",
              "4   1992-06-18      2  dominicks -79654.61  4453.13 88560.87"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# forecast returns the predictions for all specified quantiles\n",
        "# use 0.025 and 0.975 for the 95% confidence interval\n",
        "model.quantiles = [0.025, 0.5, 0.975]\n",
        "y_pred_quantiles = model.forecast_quantiles(test.loc[:, test.columns != target_column_name])\n",
        "y_pred_quantiles.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Responsible AI Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "__init__() got an unexpected keyword argument 'time_series_id_column_names'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mraiwidgets\u001b[39;00m \u001b[39mimport\u001b[39;00m ResponsibleAIDashboard\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mresponsibleai\u001b[39;00m \u001b[39mimport\u001b[39;00m RAIInsights, FeatureMetadata\n\u001b[1;32m----> 4\u001b[0m feature_metadata \u001b[39m=\u001b[39m FeatureMetadata(\n\u001b[0;32m      5\u001b[0m     time_series_id_column_names\u001b[39m=\u001b[39;49mtime_series_id_column_names, \n\u001b[0;32m      6\u001b[0m     categorical_features\u001b[39m=\u001b[39;49mtime_series_id_column_names,\n\u001b[0;32m      7\u001b[0m     time_column_name\u001b[39m=\u001b[39;49mtime_column_name)\n\u001b[0;32m      8\u001b[0m insights \u001b[39m=\u001b[39m RAIInsights(\n\u001b[0;32m      9\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     10\u001b[0m     train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m     11\u001b[0m     test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m     12\u001b[0m     target_column\u001b[39m=\u001b[39mtarget_column_name,\n\u001b[0;32m     13\u001b[0m     feature_metadata\u001b[39m=\u001b[39mfeature_metadata)\n\u001b[0;32m     15\u001b[0m ResponsibleAIDashboard(insights)\n",
            "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'time_series_id_column_names'"
          ]
        }
      ],
      "source": [
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights, FeatureMetadata\n",
        "\n",
        "feature_metadata = FeatureMetadata(\n",
        "    time_series_id_features=time_series_id_column_names, \n",
        "    categorical_features=time_series_id_column_names,\n",
        "    datetime_features=[time_column_name])\n",
        "insights = RAIInsights(\n",
        "    model=model,\n",
        "    train=train,\n",
        "    test=test,\n",
        "    target_column=target_column_name,\n",
        "    feature_metadata=feature_metadata)\n",
        "\n",
        "ResponsibleAIDashboard(insights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "jialiu"
      }
    ],
    "categories": [
      "SDK v1",
      "how-to-use-azureml",
      "automated-machine-learning"
    ],
    "category": "tutorial",
    "celltoolbar": "Raw Cell Format",
    "compute": [
      "Remote"
    ],
    "datasets": [
      "Orange Juice Sales"
    ],
    "deployment": [
      "Azure Container Instance"
    ],
    "exclude_from_index": false,
    "framework": [
      "Azure ML AutoML"
    ],
    "friendly_name": "Forecasting orange juice sales with deployment",
    "index_order": 1,
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "rai-forecasting-bug-bash-att2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "tags": [
      "None"
    ],
    "task": "Forecasting",
    "vscode": {
      "interpreter": {
        "hash": "8d82f6a81c21ef8198de58f112551c27ca8aa5960d31b7d360b8f62fe7c2fbc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
