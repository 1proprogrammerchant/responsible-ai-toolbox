{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Responsible AI dashboard for Time Series Forecasting\n",
        "_**Orange Juice Sales Forecasting**_\n",
        "\n",
        "## Contents\n",
        "1. [Introduction](#introduction)\n",
        "1. [Data](#data)\n",
        "1. [Train](#train)\n",
        "1. [Forecast](#forecast)\n",
        "1. [Responsible AI Dashboard](#analyze)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction<a id=\"introduction\"></a>\n",
        "In this example, we use sktime to train, select, and operationalize a time-series forecasting model for multiple time-series.\n",
        "\n",
        "The examples in the follow code samples use the University of Chicago's Dominick's Finer Foods dataset to forecast orange juice sales. Dominick's was a grocery chain in the Chicago metropolitan area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1670990788014
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sktime.forecasting.arima import AutoARIMA\n",
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data<a id=\"data\"></a>\n",
        "You are now ready to load the historical orange juice sales data. We will load the CSV file into a plain pandas DataFrame; the time column in the CSV is called _WeekStarting_, so it will be specially parsed into the datetime type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1670990899201
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Advert</th>\n",
              "      <th>Price</th>\n",
              "      <th>Age60</th>\n",
              "      <th>COLLEGE</th>\n",
              "      <th>INCOME</th>\n",
              "      <th>Hincome150</th>\n",
              "      <th>Large HH</th>\n",
              "      <th>Minorities</th>\n",
              "      <th>WorkingWoman</th>\n",
              "      <th>SSTRDIST</th>\n",
              "      <th>SSTRVOL</th>\n",
              "      <th>CPDIST5</th>\n",
              "      <th>CPWVOL5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Store</th>\n",
              "      <th>Brand</th>\n",
              "      <th>WeekStarting</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">2</th>\n",
              "      <th rowspan=\"10\" valign=\"top\">dominicks</th>\n",
              "      <th>1990-06-14</th>\n",
              "      <td>10560.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.590000</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-06-21</th>\n",
              "      <td>10133.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.773333</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-06-28</th>\n",
              "      <td>9706.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.956667</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-07-05</th>\n",
              "      <td>9280.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.140000</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-07-12</th>\n",
              "      <td>8853.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2.323333</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-07-19</th>\n",
              "      <td>8426.666667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>2.506667</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-07-26</th>\n",
              "      <td>8000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-08-02</th>\n",
              "      <td>6848.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.090000</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-08-09</th>\n",
              "      <td>2880.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.090000</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-08-16</th>\n",
              "      <td>2240.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.090000</td>\n",
              "      <td>0.232865</td>\n",
              "      <td>0.248935</td>\n",
              "      <td>10.553205</td>\n",
              "      <td>0.463887</td>\n",
              "      <td>0.103953</td>\n",
              "      <td>0.11428</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>2.110122</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.92728</td>\n",
              "      <td>0.376927</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Quantity    Advert     Price     Age60  \\\n",
              "Store Brand     WeekStarting                                               \n",
              "2     dominicks 1990-06-14    10560.000000  1.000000  1.590000  0.232865   \n",
              "                1990-06-21    10133.333333  0.833333  1.773333  0.232865   \n",
              "                1990-06-28     9706.666667  0.666667  1.956667  0.232865   \n",
              "                1990-07-05     9280.000000  0.500000  2.140000  0.232865   \n",
              "                1990-07-12     8853.333333  0.333333  2.323333  0.232865   \n",
              "                1990-07-19     8426.666667  0.166667  2.506667  0.232865   \n",
              "                1990-07-26     8000.000000  0.000000  2.690000  0.232865   \n",
              "                1990-08-02     6848.000000  1.000000  2.090000  0.232865   \n",
              "                1990-08-09     2880.000000  0.000000  2.090000  0.232865   \n",
              "                1990-08-16     2240.000000  0.000000  2.090000  0.232865   \n",
              "\n",
              "                               COLLEGE     INCOME  Hincome150  Large HH  \\\n",
              "Store Brand     WeekStarting                                              \n",
              "2     dominicks 1990-06-14    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-06-21    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-06-28    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-07-05    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-07-12    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-07-19    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-07-26    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-08-02    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-08-09    0.248935  10.553205    0.463887  0.103953   \n",
              "                1990-08-16    0.248935  10.553205    0.463887  0.103953   \n",
              "\n",
              "                              Minorities  WorkingWoman  SSTRDIST   SSTRVOL  \\\n",
              "Store Brand     WeekStarting                                                 \n",
              "2     dominicks 1990-06-14       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-06-21       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-06-28       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-07-05       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-07-12       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-07-19       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-07-26       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-08-02       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-08-09       0.11428      0.303585  2.110122  1.142857   \n",
              "                1990-08-16       0.11428      0.303585  2.110122  1.142857   \n",
              "\n",
              "                              CPDIST5   CPWVOL5  \n",
              "Store Brand     WeekStarting                     \n",
              "2     dominicks 1990-06-14    1.92728  0.376927  \n",
              "                1990-06-21    1.92728  0.376927  \n",
              "                1990-06-28    1.92728  0.376927  \n",
              "                1990-07-05    1.92728  0.376927  \n",
              "                1990-07-12    1.92728  0.376927  \n",
              "                1990-07-19    1.92728  0.376927  \n",
              "                1990-07-26    1.92728  0.376927  \n",
              "                1990-08-02    1.92728  0.376927  \n",
              "                1990-08-09    1.92728  0.376927  \n",
              "                1990-08-16    1.92728  0.376927  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "time_column_name = \"WeekStarting\"\n",
        "time_series_id_column_names = [\"Store\", \"Brand\"]\n",
        "dataset_location = \"https://raw.githubusercontent.com/Azure/azureml-examples/2fe81643865e1f4591e7734bd1a729093cafb826/v1/python-sdk/tutorials/automl-with-azureml/forecasting-orange-juice-sales/dominicks_OJ.csv\"\n",
        "data = pd.read_csv(dataset_location, parse_dates=[time_column_name])\n",
        "\n",
        "# Drop the columns 'logQuantity' as it is a leaky feature.\n",
        "data.drop(\"logQuantity\", axis=1, inplace=True)\n",
        "\n",
        "# Set up multi index with time series ID columns and time column.\n",
        "data.set_index(time_series_id_column_names + [time_column_name], inplace=True, drop=True)\n",
        "data = data.groupby(time_series_id_column_names).apply(lambda group: group.loc[group.name].asfreq(\"W-THU\").interpolate())\n",
        "data.sort_index(inplace=True, ascending=[True, True, True])\n",
        "\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each row in the DataFrame holds a quantity of weekly sales for an OJ brand at a single store. The data also includes the sales price, a flag indicating if the OJ brand was advertised in the store that week, and some customer demographic information based on the store location. For historical reasons, the data also include the logarithm of the sales quantity. The Dominick's grocery data is commonly used to illustrate econometric modeling techniques where logarithms of quantities are generally preferred.    \n",
        "\n",
        "The task is now to build a time-series model for the _Quantity_ column. It is important to note that this dataset is comprised of many individual time-series - one for each unique combination of _Store_ and _Brand_. To distinguish the individual time-series, we define the **time_series_id_column_names** - the columns whose values determine the boundaries between time-series: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1670990902872
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data contains 249 individual time-series.\n"
          ]
        }
      ],
      "source": [
        "nseries = data.groupby(time_series_id_column_names).ngroups\n",
        "print(\"Data contains {0} individual time-series.\".format(nseries))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For demonstration purposes, we extract sales time-series for just a few of the stores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1670990905562
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data subset contains 9 individual time-series.\n"
          ]
        }
      ],
      "source": [
        "use_stores = [2, 5, 8]\n",
        "use_brands = ['tropicana', 'dominicks', 'minute.maid']\n",
        "data_subset = data.loc[(use_stores, use_brands, slice(None)), :]\n",
        "nseries = data_subset.groupby(time_series_id_column_names).ngroups\n",
        "print(f\"Data subset contains {nseries} individual time-series.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Splitting\n",
        "We now split the data into a training and a testing set for later forecast evaluation. The test set will contain the final 20 weeks of observed sales for each time-series. The splits should be stratified by series, so we use a group-by statement on the time series identifier columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1670990907583
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_utilities.py:42: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  return X.loc[tuple(list(X.index[0])[:-1])].index\n"
          ]
        }
      ],
      "source": [
        "target_column_name = \"Quantity\"\n",
        "\n",
        "y = pd.DataFrame(data_subset[target_column_name])\n",
        "X = data_subset.drop(columns=[target_column_name])\n",
        "fh_dates = pd.DatetimeIndex(y.index.get_level_values(2).unique().sort_values().to_list()[-20:], freq='W-THU')\n",
        "fh = ForecastingHorizon(fh_dates, is_relative=False)\n",
        "y_train, y_test, X_train, X_test = \\\n",
        "    temporal_train_test_split(\n",
        "        y=y,\n",
        "        X=X,\n",
        "        test_size=20)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling\n",
        "\n",
        "For forecasting tasks, we need to do several pre-processing and estimation steps that are specific to time-series including:\n",
        "* Detect time-series sample frequency (e.g. hourly, daily, weekly) and create new records for absent time points to make the series regular. A regular time series has a well-defined frequency and has a value at every sample point in a contiguous time span \n",
        "* Impute missing values in the target (via forward-fill) and feature columns (using median column values) \n",
        "* Create features based on time series identifiers to enable fixed effects across different series\n",
        "* Create time-based features to assist in learning seasonal patterns\n",
        "* Encode categorical variables to numeric quantities\n",
        "\n",
        "In this notebook, we will train a single, regression-type model across **all** time-series in a given training set. This allows the model to generalize across related series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customization\n",
        "\n",
        "The featurization customization in forecasting is an advanced feature in AutoML which allows our customers to change the default forecasting featurization behaviors and column types through `FeaturizationConfig`. The supported scenarios include:\n",
        "\n",
        "1. Column purposes update: Override feature type for the specified column. Currently supports DateTime, Categorical and Numeric. This customization can be used in the scenario that the type of the column cannot correctly reflect its purpose. Some numerical columns, for instance, can be treated as Categorical columns which need to be converted to categorical while some can be treated as epoch timestamp which need to be converted to datetime. To tell our SDK to correctly preprocess these columns, a configuration need to be add with the columns and their desired types.\n",
        "2. Transformer parameters update: Currently supports parameter change for Imputer only. User can customize imputation methods. The supported imputing methods for target column are constant and ffill (forward fill). The supported imputing methods for feature columns are mean, median, most frequent, constant and ffill (forward fill). This customization can be used for the scenario that our customers know which imputation methods fit best to the input data. For instance, some datasets use NaN to represent 0 which the correct behavior should impute all the missing value with 0. To achieve this behavior, these columns need to be configured as constant imputation with `fill_value` 0.\n",
        "3. Drop columns: Columns to drop from being featurized. These usually are the columns which are leaky or the columns contain no useful data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1670990927322
        },
        "tags": [
          "sample-featurizationconfig-remarks"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nfeaturization_config = FeaturizationConfig()\\n# Force the CPWVOL5 feature to be numeric type.\\nfeaturization_config.add_column_purpose(\"CPWVOL5\", \"Numeric\")\\n# Fill missing values in the target column, Quantity, with zeros.\\nfeaturization_config.add_transformer_params(\\n    \"Imputer\", [\"Quantity\"], {\"strategy\": \"constant\", \"fill_value\": 0}\\n)\\n# Fill missing values in the INCOME column with median value.\\nfeaturization_config.add_transformer_params(\\n    \"Imputer\", [\"INCOME\"], {\"strategy\": \"median\"}\\n)\\n# Fill missing values in the Price column with forward fill (last value carried forward).\\nfeaturization_config.add_transformer_params(\"Imputer\", [\"Price\"], {\"strategy\": \"ffill\"})\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#forecaster = TransformedTargetForecaster(steps=[\n",
        "#    # (\"detrend\", Detrender()),\n",
        "#    # (\"deseasonalize\", Deseasonalizer()),\n",
        "#    # (\"minmax\", TabularToSeriesAdaptor(MinMaxScaler((1, 10)))),\n",
        "#    # (\"power\", TabularToSeriesAdaptor(PowerTransformer())),\n",
        "#    # (\"scaler\", TabularToSeriesAdaptor(RobustScaler())),\n",
        "#    (\"forecaster\", DirectTabularRegressionForecaster(KNeighborsTimeSeriesRegressor())),\n",
        "#])\n",
        "\n",
        "\"\"\"\n",
        "featurization_config = FeaturizationConfig()\n",
        "# Force the CPWVOL5 feature to be numeric type.\n",
        "featurization_config.add_column_purpose(\"CPWVOL5\", \"Numeric\")\n",
        "# Fill missing values in the target column, Quantity, with zeros.\n",
        "featurization_config.add_transformer_params(\n",
        "    \"Imputer\", [\"Quantity\"], {\"strategy\": \"constant\", \"fill_value\": 0}\n",
        ")\n",
        "# Fill missing values in the INCOME column with median value.\n",
        "featurization_config.add_transformer_params(\n",
        "    \"Imputer\", [\"INCOME\"], {\"strategy\": \"median\"}\n",
        ")\n",
        "# Fill missing values in the Price column with forward fill (last value carried forward).\n",
        "featurization_config.add_transformer_params(\"Imputer\", [\"Price\"], {\"strategy\": \"ffill\"})\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forecasting Parameters\n",
        "To define forecasting parameters for your experiment training, you can leverage the ForecastingParameters class. The table below details the forecasting parameter we will be passing into our experiment.\n",
        "\n",
        "\n",
        "|Property|Description|\n",
        "|-|-|\n",
        "|**time_column_name**|The name of your time column.|\n",
        "|**forecast_horizon**|The forecast horizon is how many periods forward you would like to forecast. This integer horizon is in units of the timeseries frequency (e.g. daily, weekly).|\n",
        "|**time_series_id_column_names**|The column names used to uniquely identify the time series in data that has multiple rows with the same timestamp. If the time series identifiers are not defined, the data set is assumed to be one time series.|\n",
        "|**freq**|Forecast frequency. This optional parameter represents the period with which the forecast is desired, for example, daily, weekly, yearly, etc. Use this parameter for the correction of time series containing irregular data points or for padding of short time series. The frequency needs to be a pandas offset alias. Please refer to [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects) for more information.\n",
        "|**cv_step_size**|Number of periods between two consecutive cross-validation folds. The default value is \"auto\", in which case AutoMl determines the cross-validation step size automatically, if a validation set is not provided. Or users could specify an integer value."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train<a id=\"train\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now submit a new training run. Depending on the data and number of iterations this operation may take several minutes.\n",
        "Information from each iteration will be printed to the console.  Validation errors and current status will be shown when setting `show_output=True` and the execution will be synchronous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n",
            "indexing past lexsort depth may impact performance.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'dominicks'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'dominicks'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[39m=\u001b[39m AutoARIMA(suppress_warnings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, error_action\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m model\u001b[39m.\u001b[39mfit(y\u001b[39m=\u001b[39my_train, X\u001b[39m=\u001b[39mX_train, fh\u001b[39m=\u001b[39mfh)\n\u001b[1;32m----> 9\u001b[0m model\u001b[39m.\u001b[39;49mpredict(fh\u001b[39m=\u001b[39;49mfh, X\u001b[39m=\u001b[39;49mX_test\u001b[39m.\u001b[39;49miloc[:\u001b[39m20\u001b[39;49m])\u001b[39m.\u001b[39mhead()\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:407\u001b[0m, in \u001b[0;36mBaseForecaster.predict\u001b[1;34m(self, fh, X)\u001b[0m\n\u001b[0;32m    404\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict(fh\u001b[39m=\u001b[39mfh, X\u001b[39m=\u001b[39mX_inner)\n\u001b[0;32m    405\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[39m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize(\u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X\u001b[39m=\u001b[39;49mX_inner, fh\u001b[39m=\u001b[39;49mfh)\n\u001b[0;32m    409\u001b[0m \u001b[39m# convert to output mtype, identical with last y mtype seen\u001b[39;00m\n\u001b[0;32m    410\u001b[0m y_out \u001b[39m=\u001b[39m convert_to(\n\u001b[0;32m    411\u001b[0m     y_pred,\n\u001b[0;32m    412\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_mtype_last_seen,\n\u001b[0;32m    413\u001b[0m     store\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_converter_store_y,\n\u001b[0;32m    414\u001b[0m     store_behaviour\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfreeze\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    415\u001b[0m )\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:1770\u001b[0m, in \u001b[0;36mBaseForecaster._vectorize\u001b[1;34m(self, methodname, **kwargs)\u001b[0m\n\u001b[0;32m   1767\u001b[0m \u001b[39mif\u001b[39;00m methodname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mupdate_predict_single\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1768\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yvec \u001b[39m=\u001b[39m y\n\u001b[1;32m-> 1770\u001b[0m y_preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_yvec\u001b[39m.\u001b[39;49mvectorize_est(\n\u001b[0;32m   1771\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecasters_, method\u001b[39m=\u001b[39;49mmethodname, return_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlist\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m   1772\u001b[0m )\n\u001b[0;32m   1774\u001b[0m \u001b[39m# if we vectorize over columns,\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[39m#   we need to replace top column level with variable names - part 1\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m m \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforecasters_\u001b[39m.\u001b[39mcolumns)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:575\u001b[0m, in \u001b[0;36mVectorizedDF.vectorize_est\u001b[1;34m(self, estimator, method, args, args_rowvec, return_type, rowname_default, colname_default, varname_of_self, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m row_ind, col_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iloc_indexer(i)\n\u001b[0;32m    574\u001b[0m args_i \u001b[39m=\u001b[39m vec_dict(args, i\u001b[39m=\u001b[39mi, vectorize_cols\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 575\u001b[0m args_i_rowvec \u001b[39m=\u001b[39m vec_dict(args_rowvec, i\u001b[39m=\u001b[39;49mi, vectorize_cols\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    576\u001b[0m args_i\u001b[39m.\u001b[39mupdate(args_i_rowvec)\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, pd\u001b[39m.\u001b[39mDataFrame):\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:569\u001b[0m, in \u001b[0;36mVectorizedDF.vectorize_est.<locals>.vec_dict\u001b[1;34m(d, i, vectorize_cols)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun\u001b[39m(v):\n\u001b[0;32m    567\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize_slice(v, i\u001b[39m=\u001b[39mi, vectorize_cols\u001b[39m=\u001b[39mvectorize_cols)\n\u001b[1;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m {k: fun(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mitems()}\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:569\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun\u001b[39m(v):\n\u001b[0;32m    567\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize_slice(v, i\u001b[39m=\u001b[39mi, vectorize_cols\u001b[39m=\u001b[39mvectorize_cols)\n\u001b[1;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m {k: fun(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mitems()}\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:567\u001b[0m, in \u001b[0;36mVectorizedDF.vectorize_est.<locals>.vec_dict.<locals>.fun\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun\u001b[39m(v):\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_slice(v, i\u001b[39m=\u001b[39;49mi, vectorize_cols\u001b[39m=\u001b[39;49mvectorize_cols)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:457\u001b[0m, in \u001b[0;36mVectorizedDF._vectorize_slice\u001b[1;34m(self, other, i, vectorize_cols)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vectorize_cols:\n\u001b[0;32m    456\u001b[0m         col_ind \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_X_at_index(row_ind\u001b[39m=\u001b[39;49mrow_ind, col_ind\u001b[39m=\u001b[39;49mcol_ind, X\u001b[39m=\u001b[39;49mother)\n\u001b[0;32m    458\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[39mreturn\u001b[39;00m other\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284\u001b[0m, in \u001b[0;36mVectorizedDF._get_X_at_index\u001b[1;34m(self, row_ind, col_ind, X)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n\u001b[0;32m    283\u001b[0m \u001b[39melif\u001b[39;00m col_ind \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     res \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mloc[row_ind]\n\u001b[0;32m    285\u001b[0m \u001b[39melif\u001b[39;00m row_ind \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     res \u001b[39m=\u001b[39m X[col_ind]\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1246\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:991\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    989\u001b[0m             \u001b[39mreturn\u001b[39;00m section\n\u001b[0;32m    990\u001b[0m         \u001b[39m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[1;32m--> 991\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(section, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)[new_key]\n\u001b[0;32m    993\u001b[0m \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mnot applicable\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1246\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:941\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[39m# we may have a nested tuples indexer here\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_nested_tuple_indexer(tup):\n\u001b[1;32m--> 941\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_nested_tuple(tup)\n\u001b[0;32m    943\u001b[0m \u001b[39m# we maybe be using a tuple to represent multiple dimensions here\u001b[39;00m\n\u001b[0;32m    944\u001b[0m ax0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1047\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_nested_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     axis \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1045\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m-> 1047\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(obj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1048\u001b[0m axis \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1050\u001b[0m \u001b[39m# if we have a scalar, we are done\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1312\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[0;32m   1259\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\generic.py:4041\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4039\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4040\u001b[0m     \u001b[39mif\u001b[39;00m drop_level:\n\u001b[1;32m-> 4041\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[0;32m   4042\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4043\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'dominicks'"
          ]
        }
      ],
      "source": [
        "# When using sktime directly we need to drop the time and time series ID columns.\n",
        "model = AutoARIMA(suppress_warnings=True, error_action=\"ignore\")\n",
        "model.fit(y=y_train, X=X_train, fh=fh)\n",
        "model.predict(fh=fh, X=X_test.iloc[:20]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n",
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n",
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n",
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n",
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n",
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n",
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n",
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n",
            "c:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
            "  res = X.loc[row_ind]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Quantiles</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0.025</th>\n",
              "      <th>0.975</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Store</th>\n",
              "      <th>Brand</th>\n",
              "      <th>WeekStarting</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">tropicana</th>\n",
              "      <th>1992-05-21</th>\n",
              "      <td>-561.552783</td>\n",
              "      <td>20217.369486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992-05-28</th>\n",
              "      <td>-561.552783</td>\n",
              "      <td>20217.369486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992-06-04</th>\n",
              "      <td>14993.607562</td>\n",
              "      <td>35772.529831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992-06-11</th>\n",
              "      <td>9023.530767</td>\n",
              "      <td>29802.453036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992-06-18</th>\n",
              "      <td>19883.956312</td>\n",
              "      <td>40662.878581</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Quantiles              \n",
              "                                     0.025         0.975\n",
              "Store Brand     WeekStarting                            \n",
              "2     tropicana 1992-05-21     -561.552783  20217.369486\n",
              "                1992-05-28     -561.552783  20217.369486\n",
              "                1992-06-04    14993.607562  35772.529831\n",
              "                1992-06-11     9023.530767  29802.453036\n",
              "                1992-06-18    19883.956312  40662.878581"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict_quantiles(fh=fh, X=X_test, alpha=[0.025, 0.975]).head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forecast<a id=\"forecast\"></a>\n",
        "\n",
        "Now that we have retrieved the best pipeline/model, it can be used to make predictions on test data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Retrieving forecasts from the model\n",
        "\n",
        "To produce predictions on the test set, we need to know the feature values at all dates in the test set. This requirement is somewhat reasonable for the OJ sales data since the features mainly consist of price, which is usually set in advance, and customer demographics which are approximately constant for each store over the 20 week forecast horizon in the testing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Try downloading the model and running forecasts locally."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Responsible AI Dashboard<a id=\"analyze\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                              Advert  Price     Age60   COLLEGE     INCOME  \\\n",
            "Store Brand     WeekStarting                                                 \n",
            "2     tropicana 1992-05-21       0.0   3.19  0.232865  0.248935  10.553205   \n",
            "\n",
            "                              Hincome150  Large HH  Minorities  WorkingWoman  \\\n",
            "Store Brand     WeekStarting                                                   \n",
            "2     tropicana 1992-05-21      0.463887  0.103953     0.11428      0.303585   \n",
            "\n",
            "                              SSTRDIST   SSTRVOL  CPDIST5   CPWVOL5  \n",
            "Store Brand     WeekStarting                                         \n",
            "2     tropicana 1992-05-21    2.110122  1.142857  1.92728  0.376927  \n"
          ]
        },
        {
          "ename": "UserConfigValidationException",
          "evalue": "The passed model cannot be used for getting predictions via forecast",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'dominicks'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\responsibleai\\responsibleai\\rai_insights\\rai_insights.py:1116\u001b[0m, in \u001b[0;36mRAIInsights._ensure_model_outputs\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   1115\u001b[0m     model_method \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, method\u001b[39m.\u001b[39mname)\n\u001b[1;32m-> 1116\u001b[0m     model_method(input_data)\n\u001b[0;32m   1117\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\responsibleai\\responsibleai\\_internal\\_forecasting_wrappers.py:85\u001b[0m, in \u001b[0;36m_WrappedForecastingModel.forecast\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[39mprint\u001b[39m(X_temp\u001b[39m.\u001b[39mhead(\u001b[39m50\u001b[39m))\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mX_temp, fh\u001b[39m=\u001b[39;49mfh)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mforecast(X)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:407\u001b[0m, in \u001b[0;36mBaseForecaster.predict\u001b[1;34m(self, fh, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[39m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize(\u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X\u001b[39m=\u001b[39;49mX_inner, fh\u001b[39m=\u001b[39;49mfh)\n\u001b[0;32m    409\u001b[0m \u001b[39m# convert to output mtype, identical with last y mtype seen\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:1770\u001b[0m, in \u001b[0;36mBaseForecaster._vectorize\u001b[1;34m(self, methodname, **kwargs)\u001b[0m\n\u001b[0;32m   1768\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yvec \u001b[39m=\u001b[39m y\n\u001b[1;32m-> 1770\u001b[0m y_preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_yvec\u001b[39m.\u001b[39;49mvectorize_est(\n\u001b[0;32m   1771\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecasters_, method\u001b[39m=\u001b[39;49mmethodname, return_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlist\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m   1772\u001b[0m )\n\u001b[0;32m   1774\u001b[0m \u001b[39m# if we vectorize over columns,\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[39m#   we need to replace top column level with variable names - part 1\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:575\u001b[0m, in \u001b[0;36mVectorizedDF.vectorize_est\u001b[1;34m(self, estimator, method, args, args_rowvec, return_type, rowname_default, colname_default, varname_of_self, **kwargs)\u001b[0m\n\u001b[0;32m    574\u001b[0m args_i \u001b[39m=\u001b[39m vec_dict(args, i\u001b[39m=\u001b[39mi, vectorize_cols\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 575\u001b[0m args_i_rowvec \u001b[39m=\u001b[39m vec_dict(args_rowvec, i\u001b[39m=\u001b[39;49mi, vectorize_cols\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    576\u001b[0m args_i\u001b[39m.\u001b[39mupdate(args_i_rowvec)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:569\u001b[0m, in \u001b[0;36mVectorizedDF.vectorize_est.<locals>.vec_dict\u001b[1;34m(d, i, vectorize_cols)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize_slice(v, i\u001b[39m=\u001b[39mi, vectorize_cols\u001b[39m=\u001b[39mvectorize_cols)\n\u001b[1;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m {k: fun(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mitems()}\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:569\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize_slice(v, i\u001b[39m=\u001b[39mi, vectorize_cols\u001b[39m=\u001b[39mvectorize_cols)\n\u001b[1;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m {k: fun(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mitems()}\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:567\u001b[0m, in \u001b[0;36mVectorizedDF.vectorize_est.<locals>.vec_dict.<locals>.fun\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun\u001b[39m(v):\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_slice(v, i\u001b[39m=\u001b[39;49mi, vectorize_cols\u001b[39m=\u001b[39;49mvectorize_cols)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:457\u001b[0m, in \u001b[0;36mVectorizedDF._vectorize_slice\u001b[1;34m(self, other, i, vectorize_cols)\u001b[0m\n\u001b[0;32m    456\u001b[0m         col_ind \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_X_at_index(row_ind\u001b[39m=\u001b[39;49mrow_ind, col_ind\u001b[39m=\u001b[39;49mcol_ind, X\u001b[39m=\u001b[39;49mother)\n\u001b[0;32m    458\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:284\u001b[0m, in \u001b[0;36mVectorizedDF._get_X_at_index\u001b[1;34m(self, row_ind, col_ind, X)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39melif\u001b[39;00m col_ind \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     res \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mloc[row_ind]\n\u001b[0;32m    285\u001b[0m \u001b[39melif\u001b[39;00m row_ind \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:991\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[39m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[1;32m--> 991\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(section, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)[new_key]\n\u001b[0;32m    993\u001b[0m \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mnot applicable\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:941\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_nested_tuple_indexer(tup):\n\u001b[1;32m--> 941\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_nested_tuple(tup)\n\u001b[0;32m    943\u001b[0m \u001b[39m# we maybe be using a tuple to represent multiple dimensions here\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1047\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_nested_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m-> 1047\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(obj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1048\u001b[0m axis \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1312\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[0;32m   1259\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\generic.py:4041\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4040\u001b[0m \u001b[39mif\u001b[39;00m drop_level:\n\u001b[1;32m-> 4041\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[0;32m   4042\u001b[0m index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sktime\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'dominicks'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mUserConfigValidationException\u001b[0m             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m test \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mjoin(y_test)\u001b[39m.\u001b[39mjoin(X_test\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mto_frame(index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m      8\u001b[0m feature_metadata \u001b[39m=\u001b[39m FeatureMetadata(\n\u001b[0;32m      9\u001b[0m     time_series_id_features\u001b[39m=\u001b[39mtime_series_id_column_names, \n\u001b[0;32m     10\u001b[0m     categorical_features\u001b[39m=\u001b[39mtime_series_id_column_names,\n\u001b[0;32m     11\u001b[0m     datetime_features\u001b[39m=\u001b[39m[time_column_name])\n\u001b[1;32m---> 12\u001b[0m insights \u001b[39m=\u001b[39m RAIInsights(\n\u001b[0;32m     13\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     14\u001b[0m     train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m     15\u001b[0m     test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m     16\u001b[0m     task_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mforecasting\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     17\u001b[0m     target_column\u001b[39m=\u001b[39;49mtarget_column_name,\n\u001b[0;32m     18\u001b[0m     feature_metadata\u001b[39m=\u001b[39;49mfeature_metadata,\n\u001b[0;32m     19\u001b[0m     forecasting_enabled\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     21\u001b[0m ResponsibleAIDashboard(insights)\n",
            "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\responsibleai\\responsibleai\\rai_insights\\rai_insights.py:220\u001b[0m, in \u001b[0;36mRAIInsights.__init__\u001b[1;34m(self, model, train, test, target_column, task_type, categorical_features, classes, serializer, maximum_rows_for_test, feature_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_large_predict_proba_output \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_large_forecast_quantiles_output \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_rai_insights_input_parameters(\n\u001b[0;32m    221\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    222\u001b[0m     train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    223\u001b[0m     test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    224\u001b[0m     target_column\u001b[39m=\u001b[39;49mtarget_column,\n\u001b[0;32m    225\u001b[0m     task_type\u001b[39m=\u001b[39;49mtask_type,\n\u001b[0;32m    226\u001b[0m     classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m    227\u001b[0m     serializer\u001b[39m=\u001b[39;49mserializer,\n\u001b[0;32m    228\u001b[0m     feature_metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_metadata,\n\u001b[0;32m    229\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_classes \u001b[39m=\u001b[39m RAIInsights\u001b[39m.\u001b[39m_get_classes(\n\u001b[0;32m    232\u001b[0m     task_type\u001b[39m=\u001b[39mtask_type,\n\u001b[0;32m    233\u001b[0m     train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    234\u001b[0m     target_column\u001b[39m=\u001b[39mtarget_column,\n\u001b[0;32m    235\u001b[0m     classes\u001b[39m=\u001b[39mclasses\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feature_columns \u001b[39m=\u001b[39m \\\n\u001b[0;32m    239\u001b[0m     test\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[target_column])\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n",
            "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\responsibleai\\responsibleai\\rai_insights\\rai_insights.py:640\u001b[0m, in \u001b[0;36mRAIInsights._validate_rai_insights_input_parameters\u001b[1;34m(self, model, train, test, target_column, task_type, classes, serializer, feature_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[39mif\u001b[39;00m task_type \u001b[39m!=\u001b[39m ModelTask\u001b[39m.\u001b[39mFORECASTING:\n\u001b[0;32m    639\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_model_outputs(input_data\u001b[39m=\u001b[39msmall_train_data)\n\u001b[1;32m--> 640\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_model_outputs(input_data\u001b[39m=\u001b[39;49msmall_test_data)\n\u001b[0;32m    642\u001b[0m \u001b[39mif\u001b[39;00m task_type \u001b[39m==\u001b[39m ModelTask\u001b[39m.\u001b[39mREGRESSION:\n\u001b[0;32m    643\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, SKLearn\u001b[39m.\u001b[39mPREDICT_PROBA):\n",
            "File \u001b[1;32mc:\\users\\roman\\git\\responsible-ai-toolbox\\responsibleai\\responsibleai\\rai_insights\\rai_insights.py:1118\u001b[0m, in \u001b[0;36mRAIInsights._ensure_model_outputs\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     model_method(input_data)\n\u001b[0;32m   1117\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m-> 1118\u001b[0m     \u001b[39mraise\u001b[39;00m UserConfigValidationException(\n\u001b[0;32m   1119\u001b[0m         _MODEL_METHOD_EXCEPTION_MESSAGE\u001b[39m.\u001b[39mformat(method\u001b[39m.\u001b[39mname))\n\u001b[0;32m   1120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features_same(input_features, input_data,\n\u001b[0;32m   1121\u001b[0m                              method\u001b[39m.\u001b[39mname)\n",
            "\u001b[1;31mUserConfigValidationException\u001b[0m: The passed model cannot be used for getting predictions via forecast"
          ]
        }
      ],
      "source": [
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights, FeatureMetadata\n",
        "\n",
        "# merge X, y, and the time and time series ID features into a single DataFrame\n",
        "train = X_train.join(y_train).join(X_train.index.to_frame(index=True))\n",
        "test = X_test.join(y_test).join(X_test.index.to_frame(index=True))\n",
        "\n",
        "feature_metadata = FeatureMetadata(\n",
        "    time_series_id_features=time_series_id_column_names, \n",
        "    categorical_features=time_series_id_column_names,\n",
        "    datetime_features=[time_column_name])\n",
        "insights = RAIInsights(\n",
        "    model=model,\n",
        "    train=train,\n",
        "    test=test,\n",
        "    task_type=\"forecasting\",\n",
        "    target_column=target_column_name,\n",
        "    feature_metadata=feature_metadata,\n",
        "    forecasting_enabled=True)\n",
        "\n",
        "ResponsibleAIDashboard(insights)"
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "jialiu"
      }
    ],
    "categories": [
      "SDK v1",
      "how-to-use-azureml",
      "automated-machine-learning"
    ],
    "category": "tutorial",
    "celltoolbar": "Raw Cell Format",
    "compute": [
      "Remote"
    ],
    "datasets": [
      "Orange Juice Sales"
    ],
    "deployment": [
      "Azure Container Instance"
    ],
    "exclude_from_index": false,
    "framework": [
      "Azure ML AutoML"
    ],
    "friendly_name": "Forecasting orange juice sales with deployment",
    "index_order": 1,
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "sktime",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "tags": [
      "None"
    ],
    "task": "Forecasting",
    "vscode": {
      "interpreter": {
        "hash": "6424d405450b15a93ca3015242fc1e51ac658b1b4015ae2fef5559269d9e1e0c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
